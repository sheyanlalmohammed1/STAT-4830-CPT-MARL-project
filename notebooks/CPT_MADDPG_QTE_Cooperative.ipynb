{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRQRq9E1Sgv5"
      },
      "source": [
        "# MADDPG with CPT Integral-Based Actor Updates in a Cooperative Multi-Agent Environment\n",
        "\n",
        "## 1. Overview\n",
        "\n",
        "This Python script implements the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm for agents in a cooperative multi-agent task, typically \"simple_spread.\" The central innovation is the application of a Cumulative Prospect Theory (CPT) valuation mechanism, specifically using a **CPT integral over empirical return distributions**, to modify the actor's (policy) loss function for *all* participating agents. This approach aims to guide policy updates based on a CPT-consistent valuation of the observed outcomes from batches of experience, rather than relying solely on instantaneous or expected Q-values.\n",
        "\n",
        "## 2. Environment: Cooperative Navigation (\"simple_spread\")\n",
        "\n",
        "The agents operate in a continuous multi-agent environment:\n",
        "\n",
        "* **Task:** The \"simple_spread\" scenario from `VmasEnv` (or `PettingZooEnv`). Agents cooperatively try to cover landmarks while minimizing collisions.\n",
        "* **Standard Grouping:** Unlike one of the previous cooperative scripts, this one appears to use the default environment grouping (e.g., a single \"agents\" group encompassing all agents), meaning all agents within this group will share the same CPT-modified loss structure.\n",
        "* **Observations & Actions:** Standard for \"simple_spread\" â€“ local observations (positions, velocities, relative entity locations) and continuous actions (velocity commands).\n",
        "* **Rewards:** Based on cooperative task performance (proximity to landmarks, collision penalties).\n",
        "\n",
        "## 3. Core Algorithm: MADDPG\n",
        "\n",
        "The foundational reinforcement learning framework is **MADDPG**:\n",
        "\n",
        "* **Actor-Critic Architecture:** Each agent (or the collective group, depending on parameter sharing) has actor networks (policies) and critic networks.\n",
        "* **Centralized Critic:** The critic typically has access to more global information (observations and actions of multiple agents) to stabilize Q-value learning.\n",
        "* **Decentralized Execution:** Actors make decisions based on their local observations.\n",
        "* **Experience Replay & Soft Target Updates:** Standard DDPG components for stable and efficient learning.\n",
        "\n",
        "## 4. Key Innovation: CPT Integral for Actor Loss Modification\n",
        "\n",
        "All agents in this setup utilize a CPT-modified DDPG loss, with the primary modification in the actor's loss calculation:\n",
        "\n",
        "* **Utility Functions (`u_plus`, `u_minus`):**\n",
        "    * Global functions are defined to transform monetary outcomes (rewards) into subjective utilities: $u_+(x) = x^\\alpha$ for gains and $u_-(x) = \\lambda(-x)^\\alpha$ for losses.\n",
        "    * These incorporate fixed parameters for utility curvature (`alpha`) and loss aversion (`lambda`).\n",
        "    * *Important Note:* While these utility functions are defined, the current implementation of `compute_cpt_integral` (which is used in the actor loss) takes `trajectory_utilities` as input. For these `u_plus` and `u_minus` functions to affect the CPT integral, the `final_returns` passed to `compute_cpt_integral` would need to be pre-processed by these utility functions. As it stands, `compute_cpt_integral` operates on the raw returns.\n",
        "* **Piecewise Linear Probability Weighting Function (`w_approx_aux`, `w_approx`):**\n",
        "    * This script employs a flexible piecewise linear probability weighting function, $w(p)$.\n",
        "    * The function `w_approx_aux(L, x)` takes a list of parameters `L` (defining slopes, intercepts, and breakpoints) and a probability `x` to return the decision weight $w(x)$.\n",
        "* **CPT Integral (`compute_cpt_integral`):**\n",
        "    * This function calculates the CPT value of a distribution of outcomes (specifically, the `final_returns` or episode rewards from the terminal states in the current training batch).\n",
        "    * It uses the provided piecewise linear weighting function parameters `w` (a tuple `(function_type, L_params)`).\n",
        "    * The integral is computed by segmenting the observed returns and summing the products of (outcome differences) and (decision weights of exceeding those outcomes).\n",
        "* **Custom DDPG Loss (`CPTDDPGLoss` for all agents):**\n",
        "    * **Actor Loss (`loss_actor`):**\n",
        "        * A `phi_factor` is computed by calling `compute_cpt_integral` with the `final_returns` from the batch (for the specific agent group) and the predefined piecewise linear weighting function parameters `self.w`.\n",
        "        * The actor's loss is then scaled using this `phi_factor`: `loss_actor = - (torch.exp(beta * phi_factor) * Q_values).mean()`. Here, `Q_values` are the critic's evaluation of the current policy's actions. This modification encourages the policy to take actions that lead to distributions of returns deemed favorable by the CPT integral valuation.\n",
        "    * **Value Loss (`loss_value`):**\n",
        "        * **Critically, the critic is trained using the standard DDPG target value.** The CPT value transformation (`C_transform`) is defined in the script but is *not* applied to the `target_value` in the critic's loss calculation within `CPTDDPGLoss`. This means the critic learns to predict standard expected Q-values, while the actor's policy is skewed by the CPT integral's valuation of outcome distributions.\n",
        "\n",
        "## 5. Experimenting with CPT Hyperparameters\n",
        "\n",
        "To explore different behavioral assumptions for the CPT-driven agents, you can adjust:\n",
        "\n",
        "1.  **Utility Function Parameters (`alpha`, `lambda` in `u_plus`, `u_minus`):**\n",
        "    * As noted above, to make these effective in the current `loss_actor` via `compute_cpt_integral`, you would need to first transform the `final_returns` using `u_plus` and `u_minus` before they are passed into `compute_cpt_integral`.\n",
        "    * **`alpha` (Utility Curvature):** Controls risk attitude.\n",
        "    * **`lambda` (Loss Aversion):** Controls the relative impact of losses versus gains.\n",
        "\n",
        "2.  **Piecewise Linear Weighting Function Parameters (`L` for `w_approx`):**\n",
        "    * This is the most direct way to shape the CPT influence in the current actor loss. The `L` parameter list is passed to `CPTDDPGLoss` during its initialization:\n",
        "        ```python\n",
        "        loss_module = CPTDDPGLoss(\n",
        "            # ...\n",
        "            w=(0, [1.946..., 0., 0.696..., ..., 0.904...]) # The list is L_params\n",
        "        )\n",
        "        ```\n",
        "    * **Structure of `L`:** `L = [s_1, i_1, ..., s_n, i_n, bp_1, ..., bp_{n-1}]` (slopes, intercepts, breakpoints).\n",
        "    * **Experimentation:**\n",
        "        * Modify the number of segments, slopes, intercepts, and breakpoints to create various probability weighting shapes (e.g., identity, overweighting small probabilities, inverse S-shape).\n",
        "        * Ensure $w(0)=0$ and $w(1)=1$ for a coherent weighting function.\n",
        "\n",
        "3.  **Beta in Actor Loss (`beta`):**\n",
        "    * The `beta` in `scale_factor = torch.exp(beta * phi_factor)` controls the sensitivity of the actor's loss to the CPT-derived `phi_factor`.\n",
        "    * Higher `beta` implies a stronger influence of the CPT valuation. `beta = 0` would effectively remove the CPT scaling from the actor loss.\n",
        "\n",
        "By adjusting these parameters, particularly the `L` list for the weighting function and the `beta` scaling factor, you can investigate how different CPT-based valuations of outcome distributions influence the learned cooperative strategies.\n",
        "\n",
        "## 6. Goal of the Code\n",
        "\n",
        "This script aims to:\n",
        "\n",
        "* Implement MADDPG in a cooperative \"simple_spread\" environment where all agents' policies are influenced by a CPT integral valuation.\n",
        "* Investigate how shaping the actor's learning objective with a CPT integral (reflecting a sophisticated valuation of empirical outcome distributions) affects cooperative behavior.\n",
        "* Explore the impact of different piecewise linear probability weighting functions on the learned policies and team performance.\n",
        "* Understand the interplay between standard Q-value estimation by the critic and CPT-influenced policy optimization by the actor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cOAimeoSBfH"
      },
      "outputs": [],
      "source": [
        "!pip3 install torchrl==0.6.0\n",
        "!pip3 install vmas\n",
        "!pip3 install pettingzoo[mpe]==1.24.3\n",
        "!pip3 install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbGSmCWdR8tn",
        "outputId": "42732dab-f890-4ecc-f519-c9fb032d7d95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.11/site-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. If you installed TorchRL from PyPI, please report the bug on TorchRL github. If you installed TorchRL locally and/or in development mode, check that you have all the required compiling packages.\n",
            "  warnings.warn(EXTENSION_WARNING)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import tempfile\n",
        "\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tensordict import TensorDictBase, is_tensor_collection\n",
        "\n",
        "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
        "from torch import multiprocessing\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyMemmapStorage, RandomSampler, ReplayBuffer\n",
        "\n",
        "from torchrl.envs import (\n",
        "    check_env_specs,\n",
        "    ExplorationType,\n",
        "    PettingZooEnv,\n",
        "    RewardSum,\n",
        "    set_exploration_type,\n",
        "    TransformedEnv,\n",
        "    VmasEnv,\n",
        ")\n",
        "\n",
        "from torchrl.modules import (\n",
        "    AdditiveGaussianModule,\n",
        "    MultiAgentMLP,\n",
        "    ProbabilisticActor,\n",
        "    TanhDelta,\n",
        ")\n",
        "\n",
        "from torchrl.objectives import DDPGLoss, SoftUpdate, ValueEstimators\n",
        "\n",
        "from torchrl.record import CSVLogger, PixelRenderTransform, VideoRecorder\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "    is_sphinx = __sphinx_build__\n",
        "except NameError:\n",
        "    is_sphinx = False\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.compiler import is_compiling\n",
        "except ImportError:\n",
        "    from torch._dynamo import is_compiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqnMXQZsR8to"
      },
      "outputs": [],
      "source": [
        "# Seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Devices\n",
        "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
        "device = (\n",
        "    torch.device(0)\n",
        "    if torch.cuda.is_available() and not is_fork\n",
        "    else torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "# Sampling\n",
        "frames_per_batch = 1000  # Number of team frames collected per sampling iteration\n",
        "n_iters = 500  # Number of sampling and training iterations\n",
        "total_frames = frames_per_batch * n_iters\n",
        "\n",
        "\n",
        "# Replay buffer\n",
        "memory_size = 1000000  # The replay buffer of each group can store this many frames\n",
        "\n",
        "# Training\n",
        "n_optimiser_steps = 42  # Number of optimization steps per training iteration\n",
        "train_batch_size = 256  # Number of frames trained in each optimiser step\n",
        "lr = 1e-4  # Learning rate\n",
        "max_grad_norm = 1 # Maximum norm for the gradients\n",
        "\n",
        "# DDPG\n",
        "gamma = 0.99  # Discount factor\n",
        "polyak_tau = 0.01  # Tau for the soft-update of the target network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE2uVUh_R8tp"
      },
      "outputs": [],
      "source": [
        "max_steps = 100  # Environment steps before done\n",
        "\n",
        "n_agents = 2\n",
        "n_landmarks = 1\n",
        "\n",
        "use_vmas = True  # Set this to True for a great performance speedup\n",
        "\n",
        "if not use_vmas:\n",
        "  base_env = PettingZooEnv(\n",
        "      task=\"simple_spread_v3\",\n",
        "      parallel=True,\n",
        "      seed=seed,\n",
        "      continuous_actions=True,\n",
        "      N = n_landmarks\n",
        "  )\n",
        "else:\n",
        "    num_vmas_envs = (\n",
        "        frames_per_batch // max_steps\n",
        "    )\n",
        "    base_env = VmasEnv(\n",
        "        scenario=\"simple_spread\",\n",
        "        num_envs=num_vmas_envs,\n",
        "        continuous_actions=True,\n",
        "        max_steps=max_steps,\n",
        "        local_ratio=0.5,\n",
        "        device=device,\n",
        "        seed=seed,\n",
        "        n_agents = n_agents\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HtYfrDbR8tp",
        "outputId": "052a0031-69b8-48e9-8e99-123017a21d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "group_map: {'agents': ['agent_0', 'agent_1']}\n"
          ]
        }
      ],
      "source": [
        "print(f\"group_map: {base_env.group_map}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4wl7ZufR8tp",
        "outputId": "eaa23f48-a58b-4627-e894-ced9b18051d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action_spec: Composite(\n",
            "    agents: Composite(\n",
            "        action: BoundedContinuous(\n",
            "            shape=torch.Size([10, 2, 2]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "reward_spec: Composite(\n",
            "    agents: Composite(\n",
            "        reward: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 2, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "done_spec: Composite(\n",
            "    done: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "observation_spec: Composite(\n",
            "    agents: Composite(\n",
            "        observation: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 2, 10]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 10]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 10]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n"
          ]
        }
      ],
      "source": [
        "print(\"action_spec:\", base_env.full_action_spec)\n",
        "print(\"reward_spec:\", base_env.full_reward_spec)\n",
        "print(\"done_spec:\", base_env.full_done_spec)\n",
        "print(\"observation_spec:\", base_env.observation_spec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1rkOHIuR8tq",
        "outputId": "a642fb81-4394-4cc1-ae78-5f94b84087fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action_keys: [('agents', 'action')]\n",
            "reward_keys: [('agents', 'reward')]\n",
            "done_keys: ['done', 'terminated']\n"
          ]
        }
      ],
      "source": [
        "print(\"action_keys:\", base_env.action_keys)\n",
        "print(\"reward_keys:\", base_env.reward_keys)\n",
        "print(\"done_keys:\", base_env.done_keys)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gqPNzI2R8tq"
      },
      "outputs": [],
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    RewardSum(\n",
        "        in_keys=base_env.reward_keys,\n",
        "        reset_keys=[\"_reset\"] * len(base_env.group_map.keys()),\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqLLs8a4R8tq",
        "outputId": "86a11661-b4cf-465c-fabb-0c2ab1960a2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-19 20:25:43,304 [torchrl][INFO] check_env_specs succeeded!\n"
          ]
        }
      ],
      "source": [
        "check_env_specs(env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-5Mkyz0R8tq",
        "outputId": "461a35ef-3816-442b-b73f-46c98100ce8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rollout of 5 steps: TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 5, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 5, 2, 10]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                agents: TensorDict(\n",
            "                    fields={\n",
            "                        episode_reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        observation: Tensor(shape=torch.Size([10, 5, 2, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "                    batch_size=torch.Size([10, 5, 2]),\n",
            "                    device=cuda:0,\n",
            "                    is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10, 5]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "Shape of the rollout TensorDict: torch.Size([10, 5])\n"
          ]
        }
      ],
      "source": [
        "n_rollout_steps = 5\n",
        "rollout = env.rollout(n_rollout_steps)\n",
        "print(f\"rollout of {n_rollout_steps} steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bI8wOC2R8tq"
      },
      "outputs": [],
      "source": [
        "policy_modules = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_policy = False  # Can change this based on the group\n",
        "\n",
        "    policy_net = MultiAgentMLP(\n",
        "        n_agent_inputs=env.observation_spec[group, \"observation\"].shape[\n",
        "            -1\n",
        "        ],  # n_obs_per_agent\n",
        "        n_agent_outputs=env.full_action_spec[group, \"action\"].shape[\n",
        "            -1\n",
        "        ],  # n_actions_per_agents\n",
        "        n_agents=len(agents),  # Number of agents in the group\n",
        "        centralised=False,  # the policies are decentralised (i.e., each agent will act from its local observation)\n",
        "        share_params=share_parameters_policy,\n",
        "        device=device,\n",
        "        depth=2,\n",
        "        num_cells=256,\n",
        "        activation_class=torch.nn.Tanh,\n",
        "    )\n",
        "\n",
        "    # Wrap the neural network in a :class:`~tensordict.nn.TensorDictModule`.\n",
        "    # This is simply a module that will read the ``in_keys`` from a tensordict, feed them to the\n",
        "    # neural networks, and write the\n",
        "    # outputs in-place at the ``out_keys``.\n",
        "\n",
        "    policy_module = TensorDictModule(\n",
        "        policy_net,\n",
        "        in_keys=[(group, \"observation\")],\n",
        "        out_keys=[(group, \"param\")],\n",
        "    )  # We just name the input and output that the network will read and write to the input tensordict\n",
        "    policy_modules[group] = policy_module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJtWd95iR8tr"
      },
      "outputs": [],
      "source": [
        "policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    policy = ProbabilisticActor(\n",
        "        module=policy_modules[group],\n",
        "        spec=env.full_action_spec[group, \"action\"],\n",
        "        in_keys=[(group, \"param\")],\n",
        "        out_keys=[(group, \"action\")],\n",
        "        distribution_class=TanhDelta,\n",
        "        distribution_kwargs={\n",
        "            \"low\": env.full_action_spec[group, \"action\"].space.low,\n",
        "            \"high\": env.full_action_spec[group, \"action\"].space.high,\n",
        "        },\n",
        "        return_log_prob=False,\n",
        "    )\n",
        "    policies[group] = policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhiuXbnjR8tr"
      },
      "outputs": [],
      "source": [
        "exploration_policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    exploration_policy = TensorDictSequential(\n",
        "        policies[group],\n",
        "        AdditiveGaussianModule(\n",
        "            spec=policies[group].spec,\n",
        "            annealing_num_steps=total_frames\n",
        "            // 2,  # Number of frames after which sigma is sigma_end\n",
        "            action_key=(group, \"action\"),\n",
        "            sigma_init=0.4,  # Initial value of the sigma\n",
        "            sigma_end=0.1,  # Final value of the sigma\n",
        "        ),\n",
        "    )\n",
        "    exploration_policies[group] = exploration_policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm5qoZm7R8tr"
      },
      "outputs": [],
      "source": [
        "critics = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_critic = True  # Can change for each group\n",
        "    MADDPG = True  # IDDPG if False, can change for each group\n",
        "\n",
        "    # This module applies the lambda function: reading the action and observation entries for the group\n",
        "    # and concatenating them in a new ``(group, \"obs_action\")`` entry\n",
        "    cat_module = TensorDictModule(\n",
        "        lambda obs, action: torch.cat([obs, action], dim=-1),\n",
        "        in_keys=[(group, \"observation\"), (group, \"action\")],\n",
        "        out_keys=[(group, \"obs_action\")],\n",
        "    )\n",
        "\n",
        "    critic_module = TensorDictModule(\n",
        "        module=MultiAgentMLP(\n",
        "            n_agent_inputs=env.observation_spec[group, \"observation\"].shape[-1]\n",
        "            + env.full_action_spec[group, \"action\"].shape[-1],\n",
        "            n_agent_outputs=1,  # 1 value per agent\n",
        "            n_agents=len(agents),\n",
        "            centralised=MADDPG,\n",
        "            share_params=share_parameters_critic,\n",
        "            device=device,\n",
        "            depth=2,\n",
        "            num_cells=256,\n",
        "            activation_class=torch.nn.Tanh,\n",
        "        ),\n",
        "        in_keys=[(group, \"obs_action\")],  # Read ``(group, \"obs_action\")``\n",
        "        out_keys=[\n",
        "            (group, \"state_action_value\")\n",
        "        ],  # Write ``(group, \"state_action_value\")``\n",
        "    )\n",
        "\n",
        "    critics[group] = TensorDictSequential(\n",
        "        cat_module, critic_module\n",
        "    )  # Run them in sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31qYnwtUR8tr",
        "outputId": "d976a842-8541-4ce5-bbfe-6303c2650c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running value and policy for group 'agents': TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 2, 12]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                param: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n"
          ]
        }
      ],
      "source": [
        "reset_td = env.reset()\n",
        "for group, _agents in env.group_map.items():\n",
        "    print(\n",
        "        f\"Running value and policy for group '{group}':\",\n",
        "        critics[group](policies[group](reset_td)),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HLLxdjTR8tr"
      },
      "outputs": [],
      "source": [
        "# Put exploration policies from each group in a sequence\n",
        "agents_exploration_policy = TensorDictSequential(*exploration_policies.values())\n",
        "\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    agents_exploration_policy,\n",
        "    device=device,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3YWxrybR8ts"
      },
      "outputs": [],
      "source": [
        "#Standard in off policy algos for efficient data collections\n",
        "replay_buffers = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    replay_buffer = ReplayBuffer(\n",
        "        storage=LazyMemmapStorage(memory_size, device=\"cpu\"),\n",
        "        sampler=RandomSampler(),\n",
        "        batch_size=train_batch_size,\n",
        "    )\n",
        "    replay_buffer.append_transform(lambda batch: batch.to(device))\n",
        "    replay_buffers[group] = replay_buffer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI57T518R8ts"
      },
      "outputs": [],
      "source": [
        "w_plus_prime_const = 0.2\n",
        "w_minus_prime_const = 0.8\n",
        "\n",
        "def u_plus(x):\n",
        "    alpha = 0.7\n",
        "    return torch.pow(x, alpha)\n",
        "\n",
        "def u_minus(x):\n",
        "    alpha = 0.95\n",
        "    lam = 2.5\n",
        "    return lam * torch.pow(-x, alpha)\n",
        "\n",
        "def w_plus_prime(p):\n",
        "    eta = 0.61\n",
        "    return eta * torch.pow(p, eta - 1)\n",
        "\n",
        "def w_minus_prime(p):\n",
        "    eta = 0.69\n",
        "    return eta * torch.pow(p, eta - 1)\n",
        "\n",
        "def compute_phi_linear(R):\n",
        "    \"\"\"\n",
        "    Compute linearized CPT sensitivity:\n",
        "    Ï†(R) â‰ˆ w'_+(p*) * u^+(R) for R>=0, and -w'_-(p*) * u^-(R) for R<0.\n",
        "    \"\"\"\n",
        "    R = R.view(-1)\n",
        "    v = torch.where(R >= 0, u_plus(R), -u_minus(R))\n",
        "    phi = torch.where(R >= 0, w_plus_prime_const * v, -w_minus_prime_const * v)\n",
        "    return phi.mean()\n",
        "\n",
        "def C_transform(x):\n",
        "    \"\"\"\n",
        "    Simple CPT transformation on one-step return:\n",
        "    C(x) â‰ˆ w'_+(p*) * u^+(x) if x >= 0, else -w'_-(p*) * u^-(x).\n",
        "    \"\"\"\n",
        "    return torch.where(x >= 0, w_plus_prime_const * u_plus(x), -w_minus_prime_const * u_minus(x))\n",
        "\n",
        "def w_approx_aux(L,x):\n",
        "    n = (len(L)+1)//3\n",
        "    breaking_points = L[2*n:]\n",
        "    for i, elt in enumerate(breaking_points):\n",
        "        if x < elt:\n",
        "            return L[2*i]*x + L[2*i+1]\n",
        "    i = n-1\n",
        "    return L[2*i]*x + L[2*i+1]\n",
        "def w_approx(L):\n",
        "    return (lambda x:w_approx_aux(L,x))\n",
        "\n",
        "\n",
        "def compute_cpt_integral(trajectory_utilities, w, batch_size):\n",
        "    \"\"\"\n",
        "    Compute the CPT integral using piecewise integration.\n",
        "\n",
        "    Args:\n",
        "        trajectory_utilities: a list or 1D tensor of utility values (episode returns).\n",
        "        w: a tuple (function_type, parameters) that defines the weighting function.\n",
        "           (We assume that a function w_approx(parameters) is available.)\n",
        "        batch_size: the number of trajectories in the batch.\n",
        "\n",
        "    Returns:\n",
        "        The estimated CPT value (a float).\n",
        "    \"\"\"\n",
        "    # Convert to a list of floats if necessary.\n",
        "    if torch.is_tensor(trajectory_utilities):\n",
        "        utilities = trajectory_utilities.tolist()\n",
        "    else:\n",
        "        utilities = [float(x) for x in trajectory_utilities]\n",
        "\n",
        "    # Determine segmentation points (include 0 plus unique outcomes).\n",
        "    segments = sorted(list(set(utilities + [0])))\n",
        "\n",
        "    # Create segments for gains (non-negative) and losses (non-positive)\n",
        "    positive_segments = sorted([x for x in segments if x >= 0])\n",
        "    negative_segments = sorted([-x for x in segments if x <= 0])\n",
        "\n",
        "    res = 0\n",
        "    if len(segments) == 0:\n",
        "        return 0\n",
        "    parameters = w[1]  # extract the parameter list from the tuple\n",
        "\n",
        "    # Integral over gains\n",
        "    for i in range(len(positive_segments) - 1):\n",
        "        count = sum(1 for x in utilities if x > positive_segments[i])\n",
        "        weight = w_approx(parameters)(count / batch_size)\n",
        "        res += weight * (positive_segments[i+1] - positive_segments[i])\n",
        "\n",
        "    # Integral over losses\n",
        "    for i in range(len(negative_segments) - 1):\n",
        "            # Calculate probability P(X <= -z_i) where z_i = negative_segments[i]\n",
        "            # Note: x <= -negative_segments[i] is equivalent to -x >= negative_segments[i]\n",
        "            count_le = sum(1 for x in utilities if x <= -negative_segments[i])\n",
        "            prob_le = count_le / batch_size\n",
        "            # Apply the weighting function w^- (assuming w_approx is w^- or handles it)\n",
        "            weight = w_approx(parameters)(prob_le) # Corrected weight calculation\n",
        "            res -= weight * (negative_segments[i+1] - negative_segments[i])\n",
        "\n",
        "    return torch.tensor(res, dtype=torch.float32, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-CZdDLCR8ts"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from tensordict import TensorDict, TensorDictBase, TensorDictParams\n",
        "from tensordict.nn import dispatch, TensorDictModule\n",
        "\n",
        "from tensordict.utils import NestedKey, unravel_key\n",
        "from torchrl.modules.tensordict_module.actors import ActorCriticWrapper\n",
        "from torchrl.objectives.common import LossModule\n",
        "from torchrl.objectives.utils import (\n",
        "    _cache_values,\n",
        "    _GAMMA_LMBDA_DEPREC_ERROR,\n",
        "    _reduce,\n",
        "    default_value_kwargs,\n",
        "    distance_loss,\n",
        "    ValueEstimators,\n",
        ")\n",
        "from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator\n",
        "\n",
        "\n",
        "class CPTDDPGLoss(LossModule):\n",
        "    \"\"\"The DDPG Loss class.\n",
        "\n",
        "    Args:\n",
        "        actor_network (TensorDictModule): a policy operator.\n",
        "        value_network (TensorDictModule): a Q value operator.\n",
        "        loss_function (str): loss function for the value discrepancy. Can be one of \"l1\", \"l2\" or \"smooth_l1\".\n",
        "        delay_actor (bool, optional): whether to separate the target actor networks from the actor networks used for\n",
        "            data collection. Default is ``False``.\n",
        "        delay_value (bool, optional): whether to separate the target value networks from the value networks used for\n",
        "            data collection. Default is ``True``.\n",
        "        separate_losses (bool, optional): if ``True``, shared parameters between\n",
        "            policy and critic will only be trained on the policy loss.\n",
        "            Defaults to ``False``, i.e., gradients are propagated to shared\n",
        "            parameters for both policy and critic losses.\n",
        "        reduction (str, optional): Specifies the reduction to apply to the output:\n",
        "            ``\"none\"`` | ``\"mean\"`` | ``\"sum\"``. ``\"none\"``: no reduction will be applied,\n",
        "            ``\"mean\"``: the sum of the output will be divided by the number of\n",
        "            elements in the output, ``\"sum\"``: the output will be summed. Default: ``\"mean\"``.\n",
        "\n",
        "    Examples:\n",
        "        >>> import torch\n",
        "        >>> from torch import nn\n",
        "        >>> from torchrl.data import Bounded\n",
        "        >>> from torchrl.modules.tensordict_module.actors import Actor, ValueOperator\n",
        "        >>> from torchrl.objectives.ddpg import DDPGLoss\n",
        "        >>> from tensordict import TensorDict\n",
        "        >>> n_act, n_obs = 4, 3\n",
        "        >>> spec = Bounded(-torch.ones(n_act), torch.ones(n_act), (n_act,))\n",
        "        >>> actor = Actor(spec=spec, module=nn.Linear(n_obs, n_act))\n",
        "        >>> class ValueClass(nn.Module):\n",
        "        ...     def __init__(self):\n",
        "        ...         super().__init__()\n",
        "        ...         self.linear = nn.Linear(n_obs + n_act, 1)\n",
        "        ...     def forward(self, obs, act):\n",
        "        ...         return self.linear(torch.cat([obs, act], -1))\n",
        "        >>> module = ValueClass()\n",
        "        >>> value = ValueOperator(\n",
        "        ...     module=module,\n",
        "        ...     in_keys=[\"observation\", \"action\"])\n",
        "        >>> loss = DDPGLoss(actor, value)\n",
        "        >>> batch = [2, ]\n",
        "        >>> data = TensorDict({\n",
        "        ...        \"observation\": torch.randn(*batch, n_obs),\n",
        "        ...        \"action\": spec.rand(batch),\n",
        "        ...        (\"next\", \"done\"): torch.zeros(*batch, 1, dtype=torch.bool),\n",
        "        ...        (\"next\", \"terminated\"): torch.zeros(*batch, 1, dtype=torch.bool),\n",
        "        ...        (\"next\", \"reward\"): torch.randn(*batch, 1),\n",
        "        ...        (\"next\", \"observation\"): torch.randn(*batch, n_obs),\n",
        "        ...    }, batch)\n",
        "        >>> loss(data)\n",
        "        TensorDict(\n",
        "            fields={\n",
        "                loss_actor: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
        "                loss_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
        "                pred_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
        "                pred_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
        "                target_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
        "                target_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
        "            batch_size=torch.Size([]),\n",
        "            device=None,\n",
        "            is_shared=False)\n",
        "\n",
        "    This class is compatible with non-tensordict based modules too and can be\n",
        "    used without recurring to any tensordict-related primitive. In this case,\n",
        "    the expected keyword arguments are:\n",
        "    ``[\"next_reward\", \"next_done\", \"next_terminated\"]`` + in_keys of the actor_network and value_network.\n",
        "    The return value is a tuple of tensors in the following order:\n",
        "    ``[\"loss_actor\", \"loss_value\", \"pred_value\", \"target_value\", \"pred_value_max\", \"target_value_max\"]``\n",
        "\n",
        "    Examples:\n",
        "        >>> import torch\n",
        "        >>> from torch import nn\n",
        "        >>> from torchrl.data import Bounded\n",
        "        >>> from torchrl.modules.tensordict_module.actors import Actor, ValueOperator\n",
        "        >>> from torchrl.objectives.ddpg import DDPGLoss\n",
        "        >>> _ = torch.manual_seed(42)\n",
        "        >>> n_act, n_obs = 4, 3\n",
        "        >>> spec = Bounded(-torch.ones(n_act), torch.ones(n_act), (n_act,))\n",
        "        >>> actor = Actor(spec=spec, module=nn.Linear(n_obs, n_act))\n",
        "        >>> class ValueClass(nn.Module):\n",
        "        ...     def __init__(self):\n",
        "        ...         super().__init__()\n",
        "        ...         self.linear = nn.Linear(n_obs + n_act, 1)\n",
        "        ...     def forward(self, obs, act):\n",
        "        ...         return self.linear(torch.cat([obs, act], -1))\n",
        "        >>> module = ValueClass()\n",
        "        >>> value = ValueOperator(\n",
        "        ...     module=module,\n",
        "        ...     in_keys=[\"observation\", \"action\"])\n",
        "        >>> loss = DDPGLoss(actor, value)\n",
        "        >>> loss_actor, loss_value, pred_value, target_value, pred_value_max, target_value_max = loss(\n",
        "        ...     observation=torch.randn(n_obs),\n",
        "        ...     action=spec.rand(),\n",
        "        ...     next_done=torch.zeros(1, dtype=torch.bool),\n",
        "        ...     next_terminated=torch.zeros(1, dtype=torch.bool),\n",
        "        ...     next_observation=torch.randn(n_obs),\n",
        "        ...     next_reward=torch.randn(1))\n",
        "        >>> loss_actor.backward()\n",
        "\n",
        "    The output keys can also be filtered using the :meth:`DDPGLoss.select_out_keys`\n",
        "    method.\n",
        "\n",
        "    Examples:\n",
        "        >>> loss.select_out_keys('loss_actor', 'loss_value')\n",
        "        >>> loss_actor, loss_value = loss(\n",
        "        ...     observation=torch.randn(n_obs),\n",
        "        ...     action=spec.rand(),\n",
        "        ...     next_done=torch.zeros(1, dtype=torch.bool),\n",
        "        ...     next_terminated=torch.zeros(1, dtype=torch.bool),\n",
        "        ...     next_observation=torch.randn(n_obs),\n",
        "        ...     next_reward=torch.randn(1))\n",
        "        >>> loss_actor.backward()\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    @dataclass\n",
        "    class _AcceptedKeys:\n",
        "        \"\"\"Maintains default values for all configurable tensordict keys.\n",
        "\n",
        "        This class defines which tensordict keys can be set using '.set_keys(key_name=key_value)' and their\n",
        "        default values.\n",
        "\n",
        "        Attributes:\n",
        "            state_action_value (NestedKey): The input tensordict key where the\n",
        "                state action value is expected. Will be used for the underlying\n",
        "                value estimator as value key. Defaults to ``\"state_action_value\"``.\n",
        "            priority (NestedKey): The input tensordict key where the target\n",
        "                priority is written to. Defaults to ``\"td_error\"``.\n",
        "            reward (NestedKey): The input tensordict key where the reward is expected.\n",
        "                Will be used for the underlying value estimator. Defaults to ``\"reward\"``.\n",
        "            done (NestedKey): The key in the input TensorDict that indicates\n",
        "                whether a trajectory is done. Will be used for the underlying value estimator.\n",
        "                Defaults to ``\"done\"``.\n",
        "            terminated (NestedKey): The key in the input TensorDict that indicates\n",
        "                whether a trajectory is terminated. Will be used for the underlying value estimator.\n",
        "                Defaults to ``\"terminated\"``.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        state_action_value: NestedKey = \"state_action_value\"\n",
        "        priority: NestedKey = \"td_error\"\n",
        "        reward: NestedKey = \"reward\"\n",
        "        done: NestedKey = \"done\"\n",
        "        terminated: NestedKey = \"terminated\"\n",
        "\n",
        "    tensor_keys: _AcceptedKeys\n",
        "    default_keys = _AcceptedKeys\n",
        "    default_value_estimator: ValueEstimators = ValueEstimators.TD0\n",
        "    out_keys = [\n",
        "        \"loss_actor\",\n",
        "        \"loss_value\",\n",
        "        \"pred_value\",\n",
        "        \"target_value\",\n",
        "        \"pred_value_max\",\n",
        "        \"target_value_max\",\n",
        "    ]\n",
        "\n",
        "    actor_network: TensorDictModule\n",
        "    value_network: actor_network\n",
        "    actor_network_params: TensorDictParams\n",
        "    value_network_params: TensorDictParams\n",
        "    target_actor_network_params: TensorDictParams\n",
        "    target_value_network_params: TensorDictParams\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        actor_network: TensorDictModule,\n",
        "        value_network: TensorDictModule,\n",
        "        *,\n",
        "        loss_function: str = \"l2\",\n",
        "        delay_actor: bool = False,\n",
        "        delay_value: bool = True,\n",
        "        gamma: float = None,\n",
        "        separate_losses: bool = False,\n",
        "        reduction: str = None,\n",
        "        w: tuple = None\n",
        "    ) -> None:\n",
        "        self.w = w\n",
        "        self._in_keys = None\n",
        "        if reduction is None:\n",
        "            reduction = \"mean\"\n",
        "        super().__init__()\n",
        "        self.delay_actor = delay_actor\n",
        "        self.delay_value = delay_value\n",
        "\n",
        "        actor_critic = ActorCriticWrapper(actor_network, value_network)\n",
        "        params = TensorDict.from_module(actor_critic)\n",
        "        params_meta = params.apply(\n",
        "            self._make_meta_params, device=torch.device(\"meta\"), filter_empty=False\n",
        "        )\n",
        "        with params_meta.to_module(actor_critic):\n",
        "            self.__dict__[\"actor_critic\"] = deepcopy(actor_critic)\n",
        "\n",
        "        self.convert_to_functional(\n",
        "            actor_network,\n",
        "            \"actor_network\",\n",
        "            create_target_params=self.delay_actor,\n",
        "        )\n",
        "        if separate_losses:\n",
        "            # we want to make sure there are no duplicates in the params: the\n",
        "            # params of critic must be refs to actor if they're shared\n",
        "            policy_params = list(actor_network.parameters())\n",
        "        else:\n",
        "            policy_params = None\n",
        "        self.convert_to_functional(\n",
        "            value_network,\n",
        "            \"value_network\",\n",
        "            create_target_params=self.delay_value,\n",
        "            compare_against=policy_params,\n",
        "        )\n",
        "        self.actor_critic.module[0] = self.actor_network\n",
        "        self.actor_critic.module[1] = self.value_network\n",
        "\n",
        "        self.actor_in_keys = actor_network.in_keys\n",
        "        self.value_exclusive_keys = set(self.value_network.in_keys) - (\n",
        "            set(self.actor_in_keys) | set(self.actor_network.out_keys)\n",
        "        )\n",
        "\n",
        "        self.loss_function = loss_function\n",
        "        self.reduction = reduction\n",
        "        if gamma is not None:\n",
        "            raise TypeError(_GAMMA_LMBDA_DEPREC_ERROR)\n",
        "\n",
        "    def _forward_value_estimator_keys(self, **kwargs) -> None:\n",
        "        if self._value_estimator is not None:\n",
        "            self._value_estimator.set_keys(\n",
        "                value=self._tensor_keys.state_action_value,\n",
        "                reward=self._tensor_keys.reward,\n",
        "                done=self._tensor_keys.done,\n",
        "                terminated=self._tensor_keys.terminated,\n",
        "            )\n",
        "        self._set_in_keys()\n",
        "\n",
        "    def _set_in_keys(self):\n",
        "        in_keys = {\n",
        "            unravel_key((\"next\", self.tensor_keys.reward)),\n",
        "            unravel_key((\"next\", self.tensor_keys.done)),\n",
        "            unravel_key((\"next\", self.tensor_keys.terminated)),\n",
        "            *self.actor_in_keys,\n",
        "            *[unravel_key((\"next\", key)) for key in self.actor_in_keys],\n",
        "            *self.value_network.in_keys,\n",
        "            *[unravel_key((\"next\", key)) for key in self.value_network.in_keys],\n",
        "        }\n",
        "        self._in_keys = sorted(in_keys, key=str)\n",
        "\n",
        "    @property\n",
        "    def in_keys(self):\n",
        "        if self._in_keys is None:\n",
        "            self._set_in_keys()\n",
        "        return self._in_keys\n",
        "\n",
        "    @in_keys.setter\n",
        "    def in_keys(self, values):\n",
        "        self._in_keys = values\n",
        "\n",
        "\n",
        "    def _clear_weakrefs(self, *tds):\n",
        "        if is_compiling():\n",
        "            # Waiting for weakrefs reconstruct to be supported by compile\n",
        "            for td in tds:\n",
        "                if isinstance(td, str):\n",
        "                    td = getattr(self, td, None)\n",
        "                if not is_tensor_collection(td):\n",
        "                    continue\n",
        "                td.clear_refs_for_compile_()\n",
        "\n",
        "    @dispatch\n",
        "    def forward(self, tensordict: TensorDictBase) -> TensorDict:\n",
        "        \"\"\"Computes the DDPG losses given a tensordict sampled from the replay buffer.\n",
        "\n",
        "        This function will also write a \"td_error\" key that can be used by prioritized replay buffers to assign\n",
        "            a priority to items in the tensordict.\n",
        "\n",
        "        Args:\n",
        "            tensordict (TensorDictBase): a tensordict with keys [\"done\", \"terminated\", \"reward\"] and the in_keys of the actor\n",
        "                and value networks.\n",
        "\n",
        "        Returns:\n",
        "            a tuple of 2 tensors containing the DDPG loss.\n",
        "\n",
        "        \"\"\"\n",
        "        loss_value, metadata = self.loss_value(tensordict)\n",
        "        loss_actor, metadata_actor = self.loss_actor(tensordict)\n",
        "        metadata.update(metadata_actor)\n",
        "        td_out = TensorDict(\n",
        "            source={\"loss_actor\": loss_actor, \"loss_value\": loss_value, **metadata},\n",
        "            batch_size=[],\n",
        "        )\n",
        "        self._clear_weakrefs(\n",
        "            tensordict,\n",
        "            td_out,\n",
        "            \"value_network_params\",\n",
        "            \"target_value_network_params\",\n",
        "            \"target_actor_network_params\",\n",
        "            \"actor_network_params\",\n",
        "        )\n",
        "        return td_out\n",
        "\n",
        "    def loss_actor(self, tensordict: TensorDictBase) -> Tuple[torch.Tensor, dict]:\n",
        "        \"\"\"Compute the CPT-modified actor loss.\"\"\"\n",
        "\n",
        "        td_copy = tensordict.select(\n",
        "            *self.actor_in_keys, *self.value_exclusive_keys, strict=False\n",
        "        ).detach()\n",
        "\n",
        "        with self.actor_network_params.to_module(self.actor_network):\n",
        "            td_copy = self.actor_network(td_copy)\n",
        "\n",
        "        with self._cached_detached_value_params.to_module(self.value_network):\n",
        "            td_copy = self.value_network(td_copy)\n",
        "\n",
        "        # Get action chosen by policy: Î¼(o)\n",
        "        actions = td_copy.get((self.actor_network.in_keys[0][0], \"action\"))\n",
        "\n",
        "        Q_values = td_copy.get(self.tensor_keys.state_action_value).squeeze(-1)\n",
        "\n",
        "        # --- Corrected CPT phi_factor Calculation ---\n",
        "        group = self.actor_network.in_keys[0][0]\n",
        "        # Identify terminal steps in the 'next' state within the batch\n",
        "        # Make sure 'done' and 'episode_reward' exist under the 'next' key for the group\n",
        "        next_done_key = (\"next\", group, \"done\")\n",
        "        next_reward_key = (\"next\", group, \"episode_reward\")\n",
        "\n",
        "        if next_done_key not in tensordict.keys(include_nested=True) or \\\n",
        "           next_reward_key not in tensordict.keys(include_nested=True):\n",
        "             # Handle case where keys might be missing (e.g., if process_batch wasn't perfect)\n",
        "             # Option 1: Default to neutral phi_factor\n",
        "             phi_factor = torch.tensor(1.0, device=tensordict.device)\n",
        "             print(f\"Warning: Missing required keys for phi_factor calculation in group {group}. Defaulting phi_factor to 1.0.\")\n",
        "             # Option 2: Raise an error\n",
        "             # raise KeyError(f\"Keys {next_done_key} or {next_reward_key} not found in tensordict.\")\n",
        "        else:\n",
        "            terminal_mask = tensordict.get(next_done_key).squeeze(-1) # Shape: [batch_size]\n",
        "            # Get episode rewards corresponding to these terminal 'next' states\n",
        "            final_returns = tensordict.get(next_reward_key)[terminal_mask].view(-1)\n",
        "\n",
        "            if final_returns.numel() > 1: # Need at least a few samples for meaningful integral\n",
        "                phi_factor = compute_cpt_integral(final_returns, self.w, final_returns.numel())\n",
        "                # Optional: Add some clamping or smoothing if phi_factor becomes extreme\n",
        "                # phi_factor = torch.clamp(phi_factor, -10.0, 10.0)\n",
        "            else:\n",
        "                # Not enough terminal samples in this batch, default to neutral\n",
        "                phi_factor = torch.tensor(1.0, device=tensordict.device)\n",
        "                # You could also use a running average phi_factor here if needed\n",
        "\n",
        "        # --- End Corrected Calculation ---\n",
        "\n",
        "        # --- Revised Actor Loss Calculation ---\n",
        "        # # Option A: Direct Scaling (Use signed phi_factor, might be unstable)\n",
        "        # loss_actor = - (phi_factor * Q_values).mean()\n",
        "\n",
        "        # Option B: Exponential Scaling (Recommended for Stability)\n",
        "        beta = 1.0 # Tune this hyperparameter\n",
        "        scale_factor = torch.exp(beta * phi_factor)\n",
        "        loss_actor = - (scale_factor * Q_values).mean()\n",
        "        # --- End Revised Actor Loss ---\n",
        "\n",
        "        # Ensure loss is a scalar\n",
        "        loss_actor = _reduce(loss_actor, self.reduction)\n",
        "\n",
        "        # Keep metadata empty for now, or add relevant info like phi_factor\n",
        "        metadata_actor = {\"phi_factor\": phi_factor.detach().item()}\n",
        "        return loss_actor, metadata_actor # Return scalar loss and metadata dict\n",
        "\n",
        "    def loss_value(self, tensordict: TensorDictBase) -> Tuple[torch.Tensor, dict]:\n",
        "        \"\"\"Compute the CPT-modified critic loss.\"\"\"\n",
        "        td_copy = tensordict.select(*self.value_network.in_keys, strict=False).detach()\n",
        "        with self.value_network_params.to_module(self.value_network):\n",
        "            self.value_network(td_copy)\n",
        "        pred_val = td_copy.get(self.tensor_keys.state_action_value).squeeze(-1)\n",
        "\n",
        "        # Standard target value calculation\n",
        "        target_value = self.value_estimator.value_estimate(\n",
        "            tensordict, target_params=self._cached_target_params\n",
        "        ).squeeze(-1)\n",
        "\n",
        "        # Apply CPT transformation\n",
        "        # target_value_CPT = C_transform(target_value)\n",
        "\n",
        "        # Compute CPT critic loss\n",
        "        loss_value = distance_loss(pred_val, target_value, loss_function=self.loss_function)\n",
        "\n",
        "        # Update tensor dictionary with CPT-transformed target\n",
        "        tensordict.set(\"target_value\", target_value, inplace=True)\n",
        "\n",
        "        # Compute TD error for prioritized replay buffer\n",
        "        td_error = (pred_val - target_value).pow(2).detach()\n",
        "        tensordict.set(self.tensor_keys.priority, td_error, inplace=True)\n",
        "\n",
        "        metadata = {\n",
        "            \"td_error\": td_error,\n",
        "            \"pred_value\": pred_val,\n",
        "            \"target_value\": target_value,\n",
        "        }\n",
        "        return _reduce(loss_value, self.reduction), metadata\n",
        "\n",
        "    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):\n",
        "        if value_type is None:\n",
        "            value_type = self.default_value_estimator\n",
        "        self.value_type = value_type\n",
        "        hp = dict(default_value_kwargs(value_type))\n",
        "        if hasattr(self, \"gamma\"):\n",
        "            hp[\"gamma\"] = self.gamma\n",
        "        hp.update(hyperparams)\n",
        "        if value_type == ValueEstimators.TD1:\n",
        "            self._value_estimator = TD1Estimator(value_network=self.actor_critic, **hp)\n",
        "        elif value_type == ValueEstimators.TD0:\n",
        "            self._value_estimator = TD0Estimator(value_network=self.actor_critic, **hp)\n",
        "        elif value_type == ValueEstimators.GAE:\n",
        "            raise NotImplementedError(\n",
        "                f\"Value type {value_type} it not implemented for loss {type(self)}.\"\n",
        "            )\n",
        "        elif value_type == ValueEstimators.TDLambda:\n",
        "            self._value_estimator = TDLambdaEstimator(\n",
        "                value_network=self.actor_critic, **hp\n",
        "            )\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown value type {value_type}\")\n",
        "\n",
        "        tensor_keys = {\n",
        "            \"value\": self.tensor_keys.state_action_value,\n",
        "            \"reward\": self.tensor_keys.reward,\n",
        "            \"done\": self.tensor_keys.done,\n",
        "            \"terminated\": self.tensor_keys.terminated,\n",
        "        }\n",
        "        self._value_estimator.set_keys(**tensor_keys)\n",
        "\n",
        "    @property\n",
        "    @_cache_values\n",
        "    def _cached_target_params(self):\n",
        "        target_params = TensorDict(\n",
        "            {\n",
        "                \"module\": {\n",
        "                    \"0\": self.target_actor_network_params,\n",
        "                    \"1\": self.target_value_network_params,\n",
        "                }\n",
        "            },\n",
        "            batch_size=self.target_actor_network_params.batch_size,\n",
        "            device=self.target_actor_network_params.device,\n",
        "        )\n",
        "        return target_params\n",
        "\n",
        "    @property\n",
        "    @_cache_values\n",
        "    def _cached_detached_value_params(self):\n",
        "        return self.value_network_params.detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0MAapenR8tu"
      },
      "outputs": [],
      "source": [
        "losses = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    loss_module = CPTDDPGLoss(\n",
        "        actor_network=policies[group],  # Use the non-explorative policies\n",
        "        value_network=critics[group],\n",
        "        delay_value=True,  # Whether to use a target network for the value\n",
        "        loss_function=\"l2\",\n",
        "        w=(0, [ 1.94671279,  0.,  0.69678392,  0.11132902,  2.70977837,\n",
        "       -1.70977837,  0.08906833,  0.90467621])\n",
        "    )\n",
        "    loss_module.set_keys(\n",
        "        state_action_value=(group, \"state_action_value\"),\n",
        "        reward=(group, \"reward\"),\n",
        "        done=(group, \"done\"),\n",
        "        terminated=(group, \"terminated\"),\n",
        "    )\n",
        "    loss_module.make_value_estimator(ValueEstimators.TD0, gamma=gamma)\n",
        "\n",
        "    losses[group] = loss_module\n",
        "\n",
        "target_updaters = {\n",
        "    group: SoftUpdate(loss, tau=polyak_tau) for group, loss in losses.items()\n",
        "}\n",
        "\n",
        "optimisers = {\n",
        "    group: {\n",
        "        \"loss_actor\": torch.optim.Adam(\n",
        "            loss.actor_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "        \"loss_value\": torch.optim.Adam(\n",
        "            loss.value_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "    }\n",
        "    for group, loss in losses.items()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtkXQBcCR8tu"
      },
      "outputs": [],
      "source": [
        "def process_batch(batch: TensorDictBase) -> TensorDictBase:\n",
        "    \"\"\"\n",
        "    If the `(group, \"terminated\")` and `(group, \"done\")` keys are not present, create them by expanding\n",
        "    `\"terminated\"` and `\"done\"`.\n",
        "    This is needed to present them with the same shape as the reward to the loss.\n",
        "    \"\"\"\n",
        "    for group in env.group_map.keys():\n",
        "        keys = list(batch.keys(True, True))\n",
        "        group_shape = batch.get_item_shape(group)\n",
        "        nested_done_key = (\"next\", group, \"done\")\n",
        "        nested_terminated_key = (\"next\", group, \"terminated\")\n",
        "        if nested_done_key not in keys:\n",
        "            batch.set(\n",
        "                nested_done_key,\n",
        "                batch.get((\"next\", \"done\")).unsqueeze(-1).expand((*group_shape, 1)),\n",
        "            )\n",
        "        if nested_terminated_key not in keys:\n",
        "            batch.set(\n",
        "                nested_terminated_key,\n",
        "                batch.get((\"next\", \"terminated\"))\n",
        "                .unsqueeze(-1)\n",
        "                .expand((*group_shape, 1)),\n",
        "            )\n",
        "    return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3gxj-4AR8tu",
        "outputId": "c1bff52e-0dd1-48ff-b953-2398f7c74327"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "episode_reward_mean_agents = -258.1698303222656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [5:01:13<00:00, 36.15s/it]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'to'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[43], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_optimiser_steps):\n\u001b[1;32m     31\u001b[0m     subdata \u001b[38;5;241m=\u001b[39m replay_buffers[group]\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m---> 32\u001b[0m     loss_vals \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loss_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_actor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     35\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_vals[loss_name]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchrl/objectives/common.py:49\u001b[0m, in \u001b[0;36m_forward_wrapper.<locals>.new_forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_exploration_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic_sampling_mode):\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensordict/nn/common.py:327\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "Cell \u001b[0;32mIn[40], line 308\u001b[0m, in \u001b[0;36mCPTDDPGLoss.forward\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the DDPG losses given a tensordict sampled from the replay buffer.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03mThis function will also write a \"td_error\" key that can be used by prioritized replay buffers to assign\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    307\u001b[0m loss_value, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_value(tensordict)\n\u001b[0;32m--> 308\u001b[0m loss_actor, metadata_actor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m metadata\u001b[38;5;241m.\u001b[39mupdate(metadata_actor)\n\u001b[1;32m    310\u001b[0m td_out \u001b[38;5;241m=\u001b[39m TensorDict(\n\u001b[1;32m    311\u001b[0m     source\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_actor\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_actor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_value, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata},\n\u001b[1;32m    312\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    313\u001b[0m )\n",
            "Cell \u001b[0;32mIn[40], line 363\u001b[0m, in \u001b[0;36mCPTDDPGLoss.loss_actor\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    360\u001b[0m final_returns \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mget(next_reward_key)[terminal_mask]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_returns\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;66;03m# Need at least a few samples for meaningful integral\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     phi_factor \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_cpt_integral\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_returns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_returns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# Optional: Add some clamping or smoothing if phi_factor becomes extreme\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# phi_factor = torch.clamp(phi_factor, -10.0, 10.0)\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# Not enough terminal samples in this batch, default to neutral\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     phi_factor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mtensordict\u001b[38;5;241m.\u001b[39mdevice)\n",
            "Cell \u001b[0;32mIn[39], line 73\u001b[0m, in \u001b[0;36mcompute_cpt_integral\u001b[0;34m(trajectory_utilities, w, batch_size)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     utilities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m trajectory_utilities]\n\u001b[0;32m---> 73\u001b[0m utilities \u001b[38;5;241m=\u001b[39m \u001b[43mv_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Determine segmentation points (include 0 plus unique outcomes).\u001b[39;00m\n\u001b[1;32m     75\u001b[0m segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(utilities \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m])))\n",
            "Cell \u001b[0;32mIn[39], line 51\u001b[0m, in \u001b[0;36mv_func\u001b[0;34m(x_tensor)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mv_func\u001b[39m(x_tensor):\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the CPT value function (u_plus, u_minus) element-wise.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     x_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mx_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mwhere(x_tensor \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, u_plus(x_tensor), \u001b[38;5;241m-\u001b[39mu_minus(x_tensor))\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
          ]
        }
      ],
      "source": [
        "pbar = tqdm(\n",
        "    total=n_iters,\n",
        "    desc=\", \".join(\n",
        "        [f\"episode_reward_mean_{group} = 0\" for group in env.group_map.keys()]\n",
        "    ),\n",
        ")\n",
        "episode_reward_mean_map = {group: [] for group in env.group_map.keys()}\n",
        "train_group_map = copy.deepcopy(env.group_map)\n",
        "\n",
        "grad_norms = []\n",
        "# Training/collection iterations\n",
        "for iteration, batch in enumerate(collector):\n",
        "    current_frames = batch.numel()\n",
        "    batch = process_batch(batch)  # Util to expand done keys if needed\n",
        "    # Loop over groups\n",
        "    for group in train_group_map.keys():\n",
        "        group_batch = batch.exclude(\n",
        "            *[\n",
        "                key\n",
        "                for _group in env.group_map.keys()\n",
        "                if _group != group\n",
        "                for key in [_group, (\"next\", _group)]\n",
        "            ]\n",
        "        )  # Exclude data from other groups\n",
        "        group_batch = group_batch.reshape(\n",
        "            -1\n",
        "        )  # This just affects the leading dimensions in batch_size of the tensordict\n",
        "        replay_buffers[group].extend(group_batch)\n",
        "\n",
        "        for _ in range(n_optimiser_steps):\n",
        "            subdata = replay_buffers[group].sample()\n",
        "            loss_vals = losses[group](subdata)\n",
        "\n",
        "            for loss_name in [\"loss_actor\", \"loss_value\"]:\n",
        "                loss = loss_vals[loss_name]\n",
        "                optimiser = optimisers[group][loss_name]\n",
        "                # print(type(phi_factor), phi_factor, isinstance(phi_factor, torch.Tensor))\n",
        "                loss.backward()\n",
        "\n",
        "                # Optional\n",
        "                params = optimiser.param_groups[0][\"params\"]\n",
        "                temp = torch.nn.utils.clip_grad_norm_(params, max_grad_norm)\n",
        "                total_norm = 0.0\n",
        "                # for p in params:\n",
        "                #     if p.grad is not None:\n",
        "                #         total_norm += p.grad.data.norm(2).item() ** 2\n",
        "                # total_norm = total_norm ** 0.5\n",
        "                # grad_norms.append(total_norm)\n",
        "\n",
        "                optimiser.step()\n",
        "                optimiser.zero_grad()\n",
        "\n",
        "            # Soft-update the target network\n",
        "            target_updaters[group].step()\n",
        "\n",
        "        # Exploration sigma anneal update\n",
        "        exploration_policies[group][-1].step(current_frames)\n",
        "\n",
        "    # Logging\n",
        "    for group in env.group_map.keys():\n",
        "        episode_reward_mean = (\n",
        "            batch.get((\"next\", group, \"episode_reward\"))[\n",
        "                batch.get((\"next\", group, \"done\"))\n",
        "            ]\n",
        "            .mean()\n",
        "            .item()\n",
        "        )\n",
        "        episode_reward_mean_map[group].append(episode_reward_mean)\n",
        "\n",
        "    pbar.set_description(\n",
        "        \", \".join(\n",
        "            [\n",
        "                f\"episode_reward_mean_{group} = {episode_reward_mean_map[group][-1]}\"\n",
        "                for group in env.group_map.keys()\n",
        "            ]\n",
        "        ),\n",
        "        refresh=False,\n",
        "    )\n",
        "    pbar.update()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyEg35gfR8tu",
        "outputId": "4fcc8a1c-ac44-492a-a891-214c04257e12"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['agents'])\n"
          ]
        }
      ],
      "source": [
        "fig, axs = plt.subplots(1, 1)\n",
        "for i, group in enumerate(env.group_map.keys()):\n",
        "    axs.plot(episode_reward_mean_map[group], label=f\"Episode reward mean {group}\")\n",
        "    axs.set_ylabel(\"Reward\")\n",
        "    axs.legend()\n",
        "axs.set_xlabel(\"Training iterations\")\n",
        "plt.show()\n",
        "print(env.group_map.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7zvrkaR8tv",
        "outputId": "3cea190b-e923-428a-ae2a-a03e736cec38"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHFCAYAAADi7703AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBa0lEQVR4nO3dfXzO9f////thm53Z5iybk7EhM+EtRFYiMaeFFMn5uSQx3iLKRERC5ay8hd5KvJneKWlz2snmNCLk/VVOer9tyUk2EZs9f3/47fg4OuZlh7ZjG7fr5bLLxev5er5ex+P12CH3Xq/X8TpsxhgjAAAAZKtIfhcAAABQkBGWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWgDywb98+9evXT1WqVJGvr698fX119913a9CgQdq1a5fb6oiNjZXNZnMYCwsLU+/evfP0dRMTExUbG6vffvstR/Oz6ixTpozS0tKc1oeFhaldu3a5XOWdy2az5ehny5Ytf+l1snv/5dSWLVtypQYgN3jmdwHA7eadd97R0KFDFRERoeeff1733HOPbDabDh06pOXLl+u+++7TkSNHVKVKlXypb82aNQoMDMzT10hMTNTEiRPVu3dvFS9ePMfb/frrr5o+fbomTZqUd8VBSUlJDsuTJk3S5s2btWnTJofxGjVq/KXX6d+/v1q1anVL29atW1dJSUl/uQYgNxCWgFz0zTffaMiQIWrbtq1WrVqlokWL2tc1a9ZMzz77rP71r3/J19fXcj8XL16Un59fntR477335sl+c0OrVq00a9YsPfvsswoJCcmT1zDG6I8//rjp7+B2cKP30f333++wfNddd6lIkSJO4znd341UqFBBFSpUyPH86wUGBt60HsBduAwH5KIpU6bIw8ND77zzjkNQut6TTz6pcuXK2Zd79+6tYsWKaf/+/YqOjlZAQIAeeeQRSVJCQoLat2+vChUqyMfHR1WrVtWgQYN0+vRpp/1+9tlnqlOnjry9vRUeHq4ZM2Zk+/rZXYZLTU3VqFGjFB4erqJFi6p8+fIaPny4fv/9d4d5NptNQ4cO1T//+U9FRkbKz89Pf/vb3/Tpp5/a58TGxurvf/+7JCk8PNylSzqTJ09WRkaGYmNjbzr37NmzGjJkiMqXL6+iRYuqcuXKGjdunC5fvpxtzQsWLFBkZKS8vb21dOlSLVmyRDabTZs2bdKAAQNUqlQpBQYGqmfPnvr999+VkpKizp07q3jx4ipbtqxGjRql9PT0m9aVmZmp6dOnq3r16vL29laZMmXUs2dP/fe//7XPGT58uPz9/ZWamuq0fZcuXRQcHOzwWitWrFCjRo3k7++vYsWKqWXLltqzZ4/Ddlbvo1vRtGlT1axZU19++aWioqLk5+envn372uuJjo5W2bJl5evrq8jISI0ZM8bp/XKjy8Dt2rXT+vXrVbduXfn6+qp69ep67733HOZldxku6xiPHDmiNm3aqFixYgoNDdXIkSOdfu///e9/9cQTTyggIEDFixdXt27dtHPnTtlsNi1ZsuSW+4I7lAGQKzIyMoyvr69p1KiRS9v16tXLeHl5mbCwMDN16lSzceNG88UXXxhjjJk/f76ZOnWq+eSTT8zWrVvN0qVLzd/+9jcTERFhrly5Yt/Hhg0bjIeHh3nwwQdNXFyc+de//mXuu+8+U7FiRfPnv+aVKlUyvXr1si///vvvpk6dOqZ06dJm5syZZsOGDebNN980QUFBplmzZiYzM9M+V5IJCwszDRo0MCtXrjTr1q0zTZs2NZ6enubHH380xhjz888/m+eee85IMnFxcSYpKckkJSWZ8+fP37AHEyZMMJLMr7/+akaMGGE8PT3N4cOHHWpu27atffnSpUumdu3axt/f38yYMcPEx8ebl156yXh6epo2bdo47FuSKV++vKldu7b58MMPzaZNm8z3339vFi9ebCSZ8PBwM3LkSBMfH2+mTZtmPDw8TNeuXU3dunXN5MmTTUJCgnnhhReMJPPGG2/c9Pc5cOBAI8kMHTrUrF+/3ixYsMDcddddJjQ01Pz666/GGGO+++47I8ksXLjQYdtz584Zb29vExMTYx979dVXjc1mM3379jWffvqpiYuLM40aNTL+/v7mwIED9nlW76Ob6dWrl/H393cYa9KkiSlZsqQJDQ01b7/9ttm8ebPZunWrMcaYSZMmmVmzZpnPPvvMbNmyxSxYsMCEh4ebhx9+2GEfWb/X61WqVMlUqFDB1KhRw7z//vvmiy++ME8++aSRZN+/McZs3rzZSDKbN292qLNo0aImMjLSzJgxw2zYsMG8/PLLxmazmYkTJ9rnXbhwwVStWtWULFnSzJ0713zxxRdmxIgRJjw83EgyixcvzlFfgCyEJSCXpKSkGEnmqaeeclqXkZFh0tPT7T/XB5BevXoZSea9996z3H9mZqZJT083x48fN5LMv//9b/u6hg0bmnLlyplLly7Zx1JTU03JkiVvGpamTp1qihQpYnbu3Okwb9WqVUaSWbdunX1MkgkODjapqakOx12kSBEzdepU+9jrr79uJJmjR49aHlOW68PS6dOnTVBQkOnUqZNDzdeHpQULFhhJZuXKlQ77mTZtmpFk4uPjHWoOCgoyZ8+edZibFZaee+45h/EOHToYSWbmzJkO43Xq1DF169a1PI5Dhw4ZSWbIkCEO49u3bzeSzIsvvmgfq1u3romKinKYN2/ePCPJ7N+/3xhjzIkTJ4ynp6dTjWlpaSYkJMR07tzZPpbT91F2bhSWJJmNGzdabpv1vty6dauRZL777jv7uhuFJR8fH3P8+HH72KVLl0zJkiXNoEGD7GM3CkvZ/d7btGljIiIi7Mtz5841ksznn3/uMG/QoEGEJdwSLsMBblCvXj15eXnZf9544w2nOZ06dXIaO3XqlAYPHqzQ0FB5enrKy8tLlSpVkiQdOnRIkvT7779r586devzxx+Xj42PfNiAgQI8++uhNa/v0009Vs2ZN1alTRxkZGfafli1bZnv57OGHH1ZAQIB9OTg4WGXKlNHx48dz1IubKVWqlF544QWtXr1a27dvz3bOpk2b5O/vryeeeMJhPOvy4saNGx3GmzVrphIlSmS7rz9/yi4yMlKS1LZtW6fxmx3j5s2bHerI0qBBA0VGRjrU1adPHyUmJurw4cP2scWLF+u+++5TzZo1JUlffPGFMjIy1LNnT4ffjY+Pj5o0aZLtpc3s3ke3qkSJEmrWrJnT+E8//aSnn35aISEh8vDwkJeXl5o0aSLp/96XVurUqaOKFSval318fFStWrUcvYdsNpvT+7p27doO227dulUBAQFON5d37dr1pvsHskNYAnJJ6dKl5evrm+1/8D/88EPt3LlTn3zySbbb+vn5OX1CLTMzU9HR0YqLi9Po0aO1ceNG7dixQ9u2bZMkXbp0SZJ07tw5ZWZmZntDdE5ukv7ll1+0b98+hzDn5eWlgIAAGWOc7o8qVaqU0z68vb3t9eSG4cOHq1y5cho9enS268+cOaOQkBCn+2HKlCkjT09PnTlzxmG8bNmyN3ytkiVLOixn3WuW3fgff/xhWXfW62b3euXKlXOoq1u3bvL29rbfP3Pw4EHt3LlTffr0sc/55ZdfJEn33Xef0+9nxYoVTr+b7N5Hf0V2x3HhwgU1btxY27dv1+TJk7Vlyxbt3LlTcXFxkpSj98FfeQ/5+fk5/E9B1rbX/27OnDmj4OBgp22zGwNygk/DAbnEw8NDzZo1U3x8vJKTkx3+ocn6+POxY8ey3Ta7Z9F8//33+u6777RkyRL16tXLPn7kyBGHeSVKlJDNZlNKSorTPrIb+7OskPfnG2yvX+9uvr6+io2N1cCBA/XZZ585rS9VqpS2b98uY4xD706dOqWMjAynmm/1WT+uygoBycnJTp8CO3nypENdJUqUUPv27fX+++9r8uTJWrx4sXx8fBzOfmTNX7Vqlf2MopXcPs7s9rdp0yadPHlSW7ZssZ9NkpTjZ2q5Q6lSpbRjxw6n8Zz8fQCyw5klIBeNHTtWV69e1eDBg3P0ySkrWf9QeXt7O4y/8847Dsv+/v5q0KCB4uLiHP7vOi0tTWvXrr3p67Rr104//vijSpUqpfr16zv9hIWFuVx7Vs1/5WxT37597Z+yyszMdFj3yCOP6MKFC/r4448dxt9//337+vyQdclq2bJlDuM7d+7UoUOHnOrq06ePTp48qXXr1mnZsmXq2LGjw3OpWrZsKU9PT/3444/Z/m7q16+f58f0Zzl9X+anJk2aKC0tTZ9//rnD+EcffZRPFaGw48wSkIseeOABzZ07V88995zq1q2rgQMH6p577lGRIkWUnJys1atXS1KOLpVUr15dVapU0ZgxY2SMUcmSJbV27VolJCQ4zZ00aZJatWqlFi1aaOTIkbp69aqmTZsmf39/nT171vJ1hg8frtWrV+uhhx7SiBEjVLt2bWVmZurEiROKj4/XyJEj1bBhQ5f6UKtWLUnSm2++qV69esnLy0sREREO9zrdjIeHh6ZMmaKOHTtKunZfSpaePXtq7ty56tWrl44dO6ZatWrp66+/1pQpU9SmTRs1b97cpXpzS0REhAYOHKi3335bRYoUUevWrXXs2DG99NJLCg0N1YgRIxzmR0dHq0KFChoyZIhSUlIcLsFJ1z5m/8orr2jcuHH66aef1KpVK5UoUUK//PKLduzYIX9/f02cONGdh6ioqCiVKFFCgwcP1oQJE+Tl5aUPPvhA3333nVvrsNKrVy/NmjVL3bt31+TJk1W1alV9/vnn+uKLLyRJRYpwngCu4R0D5LLBgwdr165duu+++zRr1iy1adNGrVu31ssvvyx/f39t3LhRAwcOvOl+vLy8tHbtWlWrVk2DBg1S165dderUKW3YsMFpbosWLfTxxx8rNTVVXbp0UUxMjDp16mR/Lo4Vf39/ffXVV+rdu7feffddtW3bVp07d9Zbb72lChUq3NKZpaZNm2rs2LFau3atHnzwQd13333avXu3y/vp0KGDoqKinMZ9fHy0efNmdevWTa+//rpat26tJUuWaNSoUfZ7Z/LL/Pnz9dprr2ndunVq166dxo0bp+joaCUmJjrdq1OkSBH7M5hCQ0OzPSM2duxYrVq1Sv/5z3/Uq1cvtWzZUqNHj9bx48f10EMPueuw7EqVKqXPPvtMfn5+6t69u/r27atixYppxYoVbq/lRvz9/bVp0yY1bdpUo0ePVqdOnXTixAnNmzdPklx6qjwgSTZjjMnvIgAAyGtTpkzR+PHjdeLEiVt+sjjuTFyGAwDcdubMmSPp2uXs9PR0bdq0SW+99Za6d+9OUILLCEsAgNuOn5+fZs2apWPHjuny5cuqWLGiXnjhBY0fPz6/S0MhxGU4AAAAC9zgDQAAYIGwBAAAYIGwBAAAYIEbvHNBZmamTp48qYCAALd9rQIAAPhrjDFKS0tTuXLlLB9WSljKBSdPnlRoaGh+lwEAAG7Bzz//bPlICcJSLsj6Coeff/45V7/xu7BKT09XfHy8oqOj5eXlld/l3Lbos3vQZ/egz+5Bnx2lpqYqNDT0pl/FRFjKBVmX3gIDAwlLuvaX0c/PT4GBgfxlzEP02T3os3vQZ/egz9m72S003OANAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABgodCFpXnz5ik8PFw+Pj6qV6+evvrqK8v5W7duVb169eTj46PKlStrwYIFN5z70UcfyWazqUOHDrlcNQAAKKwKVVhasWKFhg8frnHjxmnPnj1q3LixWrdurRMnTmQ7/+jRo2rTpo0aN26sPXv26MUXX9SwYcO0evVqp7nHjx/XqFGj1Lhx47w+DAAAUIgUqrA0c+ZM9evXT/3791dkZKRmz56t0NBQzZ8/P9v5CxYsUMWKFTV79mxFRkaqf//+6tu3r2bMmOEw7+rVq+rWrZsmTpyoypUru+NQAABAIVFowtKVK1e0e/duRUdHO4xHR0crMTEx222SkpKc5rds2VK7du1Senq6feyVV17RXXfdpX79+uV+4QAAoFDzzO8Ccur06dO6evWqgoODHcaDg4OVkpKS7TYpKSnZzs/IyNDp06dVtmxZffPNN1q0aJH27t2b41ouX76sy5cv25dTU1MlSenp6Q4h7E6V1QN6kbfos3vQZ/egz+5Bnx3ltA+FJixlsdlsDsvGGKexm83PGk9LS1P37t21cOFClS5dOsc1TJ06VRMnTnQaj4+Pl5+fX473c7tLSEjI7xLuCPTZPeize9Bn96DP11y8eDFH8wpNWCpdurQ8PDycziKdOnXK6exRlpCQkGzne3p6qlSpUjpw4ICOHTumRx991L4+MzNTkuTp6anDhw+rSpUqTvsdO3asYmJi7MupqakKDQ1VdHS0AgMDb/kYbxfp6elKSEhQixYt5OXlld/l3Lbos3vQZ/egz+5Bnx1lXRm6mUITlooWLap69eopISFBHTt2tI8nJCSoffv22W7TqFEjrV271mEsPj5e9evXl5eXl6pXr679+/c7rB8/frzS0tL05ptvKjQ0NNv9ent7y9vb22ncy8uLN9916Id70Gf3oM/uQZ/dgz5fk9MeFJqwJEkxMTHq0aOH6tevr0aNGundd9/ViRMnNHjwYEnXzvj873//0/vvvy9JGjx4sObMmaOYmBgNGDBASUlJWrRokZYvXy5J8vHxUc2aNR1eo3jx4pLkNA4AAO5MhSosdenSRWfOnNErr7yi5ORk1axZU+vWrVOlSpUkScnJyQ7PXAoPD9e6des0YsQIzZ07V+XKldNbb72lTp065dchAACAQqZQhSVJGjJkiIYMGZLtuiVLljiNNWnSRN9++22O95/dPgAAwJ2r0DxnCQAAID8QlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwQlgAAACwUurA0b948hYeHy8fHR/Xq1dNXX31lOX/r1q2qV6+efHx8VLlyZS1YsMBh/cKFC9W4cWOVKFFCJUqUUPPmzbVjx468PAQAAFCIFKqwtGLFCg0fPlzjxo3Tnj171LhxY7Vu3VonTpzIdv7Ro0fVpk0bNW7cWHv27NGLL76oYcOGafXq1fY5W7ZsUdeuXbV582YlJSWpYsWKio6O1v/+9z93HRYAACjAClVYmjlzpvr166f+/fsrMjJSs2fPVmhoqObPn5/t/AULFqhixYqaPXu2IiMj1b9/f/Xt21czZsywz/nggw80ZMgQ1alTR9WrV9fChQuVmZmpjRs3uuuwAABAAVZowtKVK1e0e/duRUdHO4xHR0crMTEx222SkpKc5rds2VK7du1Senp6tttcvHhR6enpKlmyZO4UDgAACjXP/C4gp06fPq2rV68qODjYYTw4OFgpKSnZbpOSkpLt/IyMDJ0+fVply5Z12mbMmDEqX768mjdvfsNaLl++rMuXL9uXU1NTJUnp6ek3DGF3kqwe0Iu8RZ/dgz67B312D/rsKKd9KDRhKYvNZnNYNsY4jd1sfnbjkjR9+nQtX75cW7ZskY+Pzw33OXXqVE2cONFpPD4+Xn5+fpb130kSEhLyu4Q7An12D/rsHvTZPejzNRcvXszRvEITlkqXLi0PDw+ns0inTp1yOnuUJSQkJNv5np6eKlWqlMP4jBkzNGXKFG3YsEG1a9e2rGXs2LGKiYmxL6empio0NFTR0dEKDAx05bBuS+np6UpISFCLFi3k5eWV3+Xctuize9Bn96DP7kGfHWVdGbqZQhOWihYtqnr16ikhIUEdO3a0jyckJKh9+/bZbtOoUSOtXbvWYSw+Pl7169d3eJO8/vrrmjx5sr744gvVr1//prV4e3vL29vbadzLy4s333Xoh3vQZ/egz+5Bn92DPl+T0x4Umhu8JSkmJkb/+Mc/9N577+nQoUMaMWKETpw4ocGDB0u6dsanZ8+e9vmDBw/W8ePHFRMTo0OHDum9997TokWLNGrUKPuc6dOna/z48XrvvfcUFhamlJQUpaSk6MKFC24/PgAAUPAUmjNLktSlSxedOXNGr7zyipKTk1WzZk2tW7dOlSpVkiQlJyc7PHMpPDxc69at04gRIzR37lyVK1dOb731ljp16mSfM2/ePF25ckVPPPGEw2tNmDBBsbGxbjkuAABQcBWqsCRJQ4YM0ZAhQ7Jdt2TJEqexJk2a6Ntvv73h/o4dO5ZLlQEAgNtRoboMBwAA4G6EJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAsuf5GuMUarVq3S5s2bderUKWVmZjqsj4uLy7XiAAAA8pvLYen555/Xu+++q4cffljBwcGy2Wx5URcAAECB4HJYWrZsmeLi4tSmTZu8qAcAAKBAcfmepaCgIFWuXDkvagEAAChwXA5LsbGxmjhxoi5dupQX9QAAABQoLl+Ge/LJJ7V8+XKVKVNGYWFh8vLyclj/7bff5lpxAAAA+c3lsNS7d2/t3r1b3bt35wZvAABw23M5LH322Wf64osv9OCDD+ZFPQAAAAWKy/cshYaGKjAwMC9qAQAAKHBcDktvvPGGRo8erWPHjuVBOQAAAAWLy5fhunfvrosXL6pKlSry8/NzusH77NmzuVYcAABAfnM5LM2ePTsPygAAACiYXApL6enp2rJli1566SUeTAkAAO4ILt2z5OXlpTVr1uRVLQAAAAWOyzd4d+zYUR9//HEelAIAAFDwuHzPUtWqVTVp0iQlJiaqXr168vf3d1g/bNiwXCsOAAAgv7kclv7xj3+oePHi2r17t3bv3u2wzmazEZYAAMBtxeWwdPTo0byoAwAAoEBy+Z6l6xljZIzJrVoAAAAKnFsKS++//75q1aolX19f+fr6qnbt2vrnP/+Z27UBAADkO5cvw82cOVMvvfSShg4dqgceeEDGGH3zzTcaPHiwTp8+rREjRuRFnQAAAPnC5bD09ttva/78+erZs6d9rH379rrnnnsUGxtLWAIAALcVly/DJScnKyoqymk8KipKycnJuVIUAABAQeFyWKpatapWrlzpNL5ixQrdfffduVIUAABAQeHyZbiJEyeqS5cu+vLLL/XAAw/IZrPp66+/1saNG7MNUQAAAIWZy2eWOnXqpO3bt6t06dL6+OOPFRcXp9KlS2vHjh3q2LFjXtQIAACQb1w+syRJ9erV07Jly3K7FgAAgALnLz2UEgAA4HaX4zNLRYoUkc1ms5xjs9mUkZHxl4sCAAAoKHIcltasWXPDdYmJiXr77bf56hMAAHDbyXFYat++vdPYDz/8oLFjx2rt2rXq1q2bJk2alKvFAQAA5Ldbumfp5MmTGjBggGrXrq2MjAzt3btXS5cuVcWKFXO7PgAAgHzlUlg6f/68XnjhBVWtWlUHDhzQxo0btXbtWtWsWTOv6gMAAMhXOb4MN336dE2bNk0hISFavnx5tpflAAAAbjc5DktjxoyRr6+vqlatqqVLl2rp0qXZzouLi8u14gAAAPJbjsNSz549b/roAAAAgNtNjsPSkiVL8rAMAACAgokneAMAAFggLAEAAFggLAEAAFggLAEAAFhwOSx9+eWX2X5ZbkZGhr788stcKQoAAKCgcDksPfzwwzp79qzT+Pnz5/Xwww/nSlEAAAAFhcthyRiT7fOWzpw5I39//1wpCgAAoKDI8XOWHn/8cUmSzWZT79695e3tbV939epV7du3T1FRUblfIQAAQD7K8ZmloKAgBQUFyRijgIAA+3JQUJBCQkI0cOBALVu2LC9rlSTNmzdP4eHh8vHxUb169fTVV19Zzt+6davq1asnHx8fVa5cWQsWLHCas3r1atWoUUPe3t6qUaOG1qxZk1flAwCAQibHZ5YWL14sSQoLC9OoUaPy5ZLbihUrNHz4cM2bN08PPPCA3nnnHbVu3VoHDx5UxYoVneYfPXpUbdq00YABA7Rs2TJ98803GjJkiO666y516tRJkpSUlKQuXbpo0qRJ6tixo9asWaPOnTvr66+/VsOGDd19iAAAoIBx+Z6lCRMm5Nu9STNnzlS/fv3Uv39/RUZGavbs2QoNDdX8+fOznb9gwQJVrFhRs2fPVmRkpPr376++fftqxowZ9jmzZ89WixYtNHbsWFWvXl1jx47VI488otmzZ7vpqAAAQEGW4zNLWX755ReNGjVKGzdu1KlTp2SMcVh/9erVXCvueleuXNHu3bs1ZswYh/Ho6GglJiZmu01SUpKio6Mdxlq2bKlFixYpPT1dXl5eSkpK0ogRI5zmWIWly5cv6/Lly/bl1NRUSVJ6errS09NdOazbUlYP6EXeos/uQZ/dgz67B312lNM+uByWevfurRMnTuill15S2bJls/1kXF44ffq0rl69quDgYIfx4OBgpaSkZLtNSkpKtvMzMjJ0+vRplS1b9oZzbrRPSZo6daomTpzoNB4fHy8/P7+cHtJtLyEhIb9LuCPQZ/egz+5Bn92DPl9z8eLFHM1zOSx9/fXX+uqrr1SnTh1XN80Vfw5nN3qUgdX8P4+7us+xY8cqJibGvpyamqrQ0FBFR0crMDDw5gdxm0tPT1dCQoJatGghLy+v/C7ntkWf3YM+uwd9dg/67CjrytDNuByWQkNDnS69uUPp0qXl4eHhdMbn1KlTTmeGsoSEhGQ739PTU6VKlbKcc6N9SpK3t7fDoxOyeHl58ea7Dv1wD/rsHvTZPeize9Dna3LaA5dv8J49e7bGjBmjY8eOubrpX1K0aFHVq1fP6dRhQkLCDZ/v1KhRI6f58fHxql+/vr1BN5rDM6MAAIB0C2eWunTpoosXL6pKlSry8/NzSmXZfRVKbomJiVGPHj1Uv359NWrUSO+++65OnDihwYMHS7p2eex///uf3n//fUnS4MGDNWfOHMXExGjAgAFKSkrSokWLtHz5cvs+n3/+eT300EOaNm2a2rdvr3//+9/asGGDvv766zw7DgAAUHi4HJby8yP1Xbp00ZkzZ/TKK68oOTlZNWvW1Lp161SpUiVJUnJysk6cOGGfHx4ernXr1mnEiBGaO3euypUrp7feesv+jCVJioqK0kcffaTx48frpZdeUpUqVbRixQqesQQAACTdQljq1atXXtSRY0OGDNGQIUOyXbdkyRKnsSZNmujbb7+13OcTTzyhJ554IjfKAwAAtxmX71mSpB9//FHjx49X165dderUKUnS+vXrdeDAgVwtDgAAIL+5HJa2bt2qWrVqafv27YqLi9OFCxckSfv27dOECRNyvUAAAID85HJYGjNmjCZPnqyEhAQVLVrUPv7www8rKSkpV4sDAADIby6Hpf3796tjx45O43fddZfOnDmTK0UBAAAUFC6HpeLFiys5OdlpfM+ePSpfvnyuFAUAAFBQuByWnn76ab3wwgtKSUmRzWZTZmamvvnmG40aNUo9e/bMixoBAADyjcth6dVXX1XFihVVvnx5XbhwQTVq1NBDDz2kqKgojR8/Pi9qBAAAyDcuP2fJy8tLH3zwgV555RXt2bNHmZmZuvfee3X33XfnRX0AAAD5yuWwlKVKlSqqUqVKbtYCAABQ4OQoLMXExGjSpEny9/dXTEyM5dyZM2fmSmEAAAAFQY7C0p49e5Senm7/843YbLbcqQoAAKCAyFFY2rx5c7Z/BgAAuN3d0nfDAQAA3ClydGbp8ccfz/EO4+LibrkYAACAgiZHZ5aCgoLsP4GBgdq4caN27dplX797925t3LhRQUFBeVYoAABAfsjRmaXFixfb//zCCy+oc+fOWrBggTw8PCRJV69e1ZAhQxQYGJg3VQIAAOQTl+9Zeu+99zRq1Ch7UJIkDw8PxcTE6L333svV4gAAAPKby2EpIyNDhw4dcho/dOiQMjMzc6UoAACAgsLlJ3j36dNHffv21ZEjR3T//fdLkrZt26bXXntNffr0yfUCAQAA8pPLYWnGjBkKCQnRrFmzlJycLEkqW7asRo8erZEjR+Z6gQAAAPnJ5bBUpEgRjR49WqNHj1ZqaqokcWM3AAC4bd3yF+lKhCQAAHD7u6WwtGrVKq1cuVInTpzQlStXHNZ9++23uVIYAABAQeDyp+Heeust9enTR2XKlNGePXvUoEEDlSpVSj/99JNat26dFzUCAADkG5fD0rx58/Tuu+9qzpw5Klq0qEaPHq2EhAQNGzZM58+fz4saAQAA8o3LYenEiROKioqSJPn6+iotLU2S1KNHDy1fvjx3qwMAAMhnLoelkJAQnTlzRpJUqVIlbdu2TZJ09OhRGWNytzoAAIB85nJYatasmdauXStJ6tevn0aMGKEWLVqoS5cu6tixY64XCAAAkJ9c/jTcu+++a/9ak8GDB6tkyZL6+uuv9eijj2rw4MG5XiAAAEB+ciksZWRk6NVXX1Xfvn0VGhoqSercubM6d+6cJ8UBAADkN5cuw3l6eur111/X1atX86oeAACAAsXle5aaN2+uLVu25EEpAAAABY/L9yy1bt1aY8eO1ffff6969erJ39/fYf1jjz2Wa8UBAADkN5fD0jPPPCNJmjlzptM6m83GJToAAHBbcTksZX0SDgAA4E7g8j1LAAAAd5Icn1m6dOmSNm7cqHbt2kmSxo4dq8uXL9vXe3h4aNKkSfLx8cn9KgEAAPJJjsPS+++/r08//dQelubMmaN77rlHvr6+kqQffvhB5cqV04gRI/KmUgAAgHyQ48twH3zwgfr27esw9uGHH2rz5s3avHmzXn/9da1cuTLXCwQAAMhPOQ5L//nPf1StWjX7so+Pj4oU+b/NGzRooIMHD+ZudQAAAPksx5fhzp8/L0/P/5v+66+/OqzPzMx0uIcJAADgdpDjM0sVKlTQ999/f8P1+/btU4UKFXKlKAAAgIIix2GpTZs2evnll/XHH384rbt06ZImTpyotm3b5mpxAAAA+S3Hl+FefPFFrVy5UhERERo6dKiqVasmm82mH374QXPmzFFGRoZefPHFvKwVAADA7XIcloKDg5WYmKhnnnlGY8aMkTFG0rWvOGnRooXmzZun4ODgPCsUAAAgP7j0dSfh4eFav369zp49qyNHjkiSqlatqpIlS+ZJcQAAAPnN5e+Gk6SSJUuqQYMGuV0LAABAgcN3wwEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFgoNGHp3Llz6tGjh4KCghQUFKQePXrot99+s9zGGKPY2FiVK1dOvr6+atq0qQ4cOGBff/bsWT333HOKiIiQn5+fKlasqGHDhun8+fN5fDQAAKCwKDRh6emnn9bevXu1fv16rV+/Xnv37lWPHj0st5k+fbpmzpypOXPmaOfOnQoJCVGLFi2UlpYmSTp58qROnjypGTNmaP/+/VqyZInWr1+vfv36ueOQAABAIXBL3w3nbocOHdL69eu1bds2NWzYUJK0cOFCNWrUSIcPH1ZERITTNsYYzZ49W+PGjdPjjz8uSVq6dKmCg4P14YcfatCgQapZs6ZWr15t36ZKlSp69dVX1b17d2VkZMjTs1C0BwAA5KFCkQaSkpIUFBRkD0qSdP/99ysoKEiJiYnZhqWjR48qJSVF0dHR9jFvb281adJEiYmJGjRoULavdf78eQUGBloGpcuXL+vy5cv25dTUVElSenq60tPTXT6+201WD+hF3qLP7kGf3YM+uwd9dpTTPhSKsJSSkqIyZco4jZcpU0YpKSk33EaSgoODHcaDg4N1/PjxbLc5c+aMJk2adMMglWXq1KmaOHGi03h8fLz8/Pwst72TJCQk5HcJdwT67B702T3os3vQ52suXryYo3n5GpZiY2OzDR3X27lzpyTJZrM5rTPGZDt+vT+vv9E2qampatu2rWrUqKEJEyZY7nPs2LGKiYlx2DY0NFTR0dEKDAy03PZOkJ6eroSEBLVo0UJeXl75Xc5tiz67B312D/rsHvTZUdaVoZvJ17A0dOhQPfXUU5ZzwsLCtG/fPv3yyy9O63799VenM0dZQkJCJF07w1S2bFn7+KlTp5y2SUtLU6tWrVSsWDGtWbPmpm8gb29veXt7O417eXnx5rsO/XAP+uwe9Nk96LN70OdrctqDfA1LpUuXVunSpW86r1GjRjp//rx27NihBg0aSJK2b9+u8+fPKyoqKtttwsPDFRISooSEBN17772SpCtXrmjr1q2aNm2afV5qaqpatmwpb29vffLJJ/Lx8cmFIwMAALeLQvHogMjISLVq1UoDBgzQtm3btG3bNg0YMEDt2rVzuLm7evXqWrNmjaRrl9+GDx+uKVOmaM2aNfr+++/Vu3dv+fn56emnn5Z07YxSdHS0fv/9dy1atEipqalKSUlRSkqKrl69mi/HCgAACpZCcYO3JH3wwQcaNmyY/dNtjz32mObMmeMw5/Dhww4PlBw9erQuXbqkIUOG6Ny5c2rYsKHi4+MVEBAgSdq9e7e2b98uSapatarDvo4ePaqwsLA8PCIAAFAYFJqwVLJkSS1btsxyjjHGYdlmsyk2NlaxsbHZzm/atKnTNgAAANcrFJfhAAAA8gthCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwEKhCUvnzp1Tjx49FBQUpKCgIPXo0UO//fab5TbGGMXGxqpcuXLy9fVV06ZNdeDAgRvObd26tWw2mz7++OPcPwAAAFAoFZqw9PTTT2vv3r1av3691q9fr71796pHjx6W20yfPl0zZ87UnDlztHPnToWEhKhFixZKS0tzmjt79mzZbLa8Kh8AABRSnvldQE4cOnRI69ev17Zt29SwYUNJ0sKFC9WoUSMdPnxYERERTtsYYzR79myNGzdOjz/+uCRp6dKlCg4O1ocffqhBgwbZ53733XeaOXOmdu7cqbJly7rnoAAAQKFQKMJSUlKSgoKC7EFJku6//34FBQUpMTEx27B09OhRpaSkKDo62j7m7e2tJk2aKDEx0R6WLl68qK5du2rOnDkKCQnJUT2XL1/W5cuX7cupqamSpPT0dKWnp9/SMd5OsnpAL/IWfXYP+uwe9Nk96LOjnPahUISllJQUlSlTxmm8TJkySklJueE2khQcHOwwHhwcrOPHj9uXR4wYoaioKLVv3z7H9UydOlUTJ050Go+Pj5efn1+O93O7S0hIyO8S7gj02T3os3vQZ/egz9dcvHgxR/PyNSzFxsZmGzqut3PnTknK9n4iY8xN7zP68/rrt/nkk0+0adMm7dmzx5WyNXbsWMXExNiXU1NTFRoaqujoaAUGBrq0r9tRenq6EhIS1KJFC3l5eeV3Obct+uwe9Nk96LN70GdHWVeGbiZfw9LQoUP11FNPWc4JCwvTvn379Msvvzit+/XXX53OHGXJuqSWkpLicB/SqVOn7Nts2rRJP/74o4oXL+6wbadOndS4cWNt2bIl2317e3vL29vbadzLy4s333Xoh3vQZ/egz+5Bn92DPl+T0x7ka1gqXbq0SpcufdN5jRo10vnz57Vjxw41aNBAkrR9+3adP39eUVFR2W4THh6ukJAQJSQk6N5775UkXblyRVu3btW0adMkSWPGjFH//v0dtqtVq5ZmzZqlRx999K8cGgAAuE0UinuWIiMj1apVKw0YMEDvvPOOJGngwIFq166dw83d1atX19SpU9WxY0fZbDYNHz5cU6ZM0d133627775bU6ZMkZ+fn55++mlJ184+ZXdTd8WKFRUeHu6egwMAAAVaoQhLkvTBBx9o2LBh9k+3PfbYY5ozZ47DnMOHD+v8+fP25dGjR+vSpUsaMmSIzp07p4YNGyo+Pl4BAQFurR0AABRehSYslSxZUsuWLbOcY4xxWLbZbIqNjVVsbGyOX+fP+wAAAHe2QvMEbwAAgPxAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALDgmd8F3A6MMZKk1NTUfK6kYEhPT9fFixeVmpoqLy+v/C7ntkWf3YM+uwd9dg/67Cjr3+2sf8dvhLCUC9LS0iRJoaGh+VwJAABwVVpamoKCgm643mZuFqdwU5mZmTp58qQCAgJks9nyu5x8l5qaqtDQUP38888KDAzM73JuW/TZPeize9Bn96DPjowxSktLU7ly5VSkyI3vTOLMUi4oUqSIKlSokN9lFDiBgYH8ZXQD+uwe9Nk96LN70Of/Y3VGKQs3eAMAAFggLAEAAFggLCHXeXt7a8KECfL29s7vUm5r9Nk96LN70Gf3oM+3hhu8AQAALHBmCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCS47d+6cevTooaCgIAUFBalHjx767bffLLcxxig2NlblypWTr6+vmjZtqgMHDtxwbuvWrWWz2fTxxx/n/gEUEnnR57Nnz+q5555TRESE/Pz8VLFiRQ0bNkznz5/P46MpOObNm6fw8HD5+PioXr16+uqrryznb926VfXq1ZOPj48qV66sBQsWOM1ZvXq1atSoIW9vb9WoUUNr1qzJq/ILjdzu88KFC9W4cWOVKFFCJUqUUPPmzbVjx468PIRCIy/e01k++ugj2Ww2dejQIZerLmQM4KJWrVqZmjVrmsTERJOYmGhq1qxp2rVrZ7nNa6+9ZgICAszq1avN/v37TZcuXUzZsmVNamqq09yZM2ea1q1bG0lmzZo1eXQUBV9e9Hn//v3m8ccfN5988ok5cuSI2bhxo7n77rtNp06d3HFI+e6jjz4yXl5eZuHChebgwYPm+eefN/7+/ub48ePZzv/pp5+Mn5+fef75583BgwfNwoULjZeXl1m1apV9TmJiovHw8DBTpkwxhw4dMlOmTDGenp5m27Zt7jqsAicv+vz000+buXPnmj179phDhw6ZPn36mKCgIPPf//7XXYdVIOVFr7McO3bMlC9f3jRu3Ni0b98+j4+kYCMswSUHDx40khz+IUhKSjKSzA8//JDtNpmZmSYkJMS89tpr9rE//vjDBAUFmQULFjjM3bt3r6lQoYJJTk6+o8NSXvf5eitXrjRFixY16enpuXcABVSDBg3M4MGDHcaqV69uxowZk+380aNHm+rVqzuMDRo0yNx///325c6dO5tWrVo5zGnZsqV56qmncqnqwicv+vxnGRkZJiAgwCxduvSvF1yI5VWvMzIyzAMPPGD+8Y9/mF69et3xYYnLcHBJUlKSgoKC1LBhQ/vY/fffr6CgICUmJma7zdGjR5WSkqLo6Gj7mLe3t5o0aeKwzcWLF9W1a1fNmTNHISEheXcQhUBe9vnPzp8/r8DAQHl63t5fFXnlyhXt3r3boT+SFB0dfcP+JCUlOc1v2bKldu3apfT0dMs5Vj2/neVVn//s4sWLSk9PV8mSJXOn8EIoL3v9yiuv6K677lK/fv1yv/BCiLAEl6SkpKhMmTJO42XKlFFKSsoNt5Gk4OBgh/Hg4GCHbUaMGKGoqCi1b98+FysunPKyz9c7c+aMJk2apEGDBv3Figu+06dP6+rVqy71JyUlJdv5GRkZOn36tOWcG+3zdpdXff6zMWPGqHz58mrevHnuFF4I5VWvv/nmGy1atEgLFy7Mm8ILIcISJEmxsbGy2WyWP7t27ZIk2Ww2p+2NMdmOX+/P66/f5pNPPtGmTZs0e/bs3DmgAiq/+3y91NRUtW3bVjVq1NCECRP+wlEVLjntj9X8P4+7us87QV70Ocv06dO1fPlyxcXFycfHJxeqLdxys9dpaWnq3r27Fi5cqNKlS+d+sYXU7X3eHTk2dOhQPfXUU5ZzwsLCtG/fPv3yyy9O63799Ven/1vJknVJLSUlRWXLlrWPnzp1yr7Npk2b9OOPP6p48eIO23bq1EmNGzfWli1bXDiagiu/+5wlLS1NrVq1UrFixbRmzRp5eXm5eiiFTunSpeXh4eH0f9zZ9SdLSEhItvM9PT1VqlQpyzk32uftLq/6nGXGjBmaMmWKNmzYoNq1a+du8YVMXvT6wIEDOnbsmB599FH7+szMTEmSp6enDh8+rCpVquTykRQC+XSvFAqprBuPt2/fbh/btm1bjm48njZtmn3s8uXLDjceJycnm/379zv8SDJvvvmm+emnn/L2oAqgvOqzMcacP3/e3H///aZJkybm999/z7uDKIAaNGhgnnnmGYexyMhIy5thIyMjHcYGDx7sdIN369atHea0atXqjr/BO7f7bIwx06dPN4GBgSYpKSl3Cy7EcrvXly5dcvpvcfv27U2zZs3M/v37zeXLl/PmQAo4whJc1qpVK1O7dm2TlJRkkpKSTK1atZw+0h4REWHi4uLsy6+99poJCgoycXFxZv/+/aZr1643fHRAFt3Bn4YzJm/6nJqaaho2bGhq1apljhw5YpKTk+0/GRkZbj2+/JD1MetFixaZgwcPmuHDhxt/f39z7NgxY4wxY8aMMT169LDPz/qY9YgRI8zBgwfNokWLnD5m/c033xgPDw/z2muvmUOHDpnXXnuNRwfkQZ+nTZtmihYtalatWuXwvk1LS3P78RUkedHrP+PTcIQl3IIzZ86Ybt26mYCAABMQEGC6detmzp075zBHklm8eLF9OTMz00yYMMGEhIQYb29v89BDD5n9+/dbvs6dHpbyos+bN282krL9OXr0qHsOLJ/NnTvXVKpUyRQtWtTUrVvXbN261b6uV69epkmTJg7zt2zZYu69915TtGhRExYWZubPn++0z3/9618mIiLCeHl5merVq5vVq1fn9WEUeLnd50qVKmX7vp0wYYIbjqZgy4v39PUIS8bYjPn/7+wCAACAEz4NBwAAYIGwBAAAYIGwBAAAYIGwBAAAYIGwBAAAYIGwBAAAYIGwBAAAYIGwBKDQa9q0qYYPH57j+ceOHZPNZtPevXvzrCYAtw/CEgC3sdlslj+9e/e+pf3GxcVp0qRJOZ4fGhqq5ORk1axZ85ZezxWrV69Ww4YNFRQUpICAAN1zzz0aOXKkfX1sbKzq1KmT53UAuHWe+V0AgDtHcnKy/c8rVqzQyy+/rMOHD9vHfH19Heanp6fLy8vrpvstWbKkS3V4eHgoJCTEpW1uxYYNG/TUU09pypQpeuyxx2Sz2XTw4EFt3Lgxz18bQO7hzBIAtwkJCbH/BAUFyWaz2Zf/+OMPFS9eXCtXrlTTpk3l4+OjZcuW6cyZM+ratasqVKggPz8/1apVS8uXL3fY758vw4WFhWnKlCnq27evAgICVLFiRb377rv29X++DLdlyxbZbDZt3LhR9evXl5+fn6KiohyCnCRNnjxZZcqUUUBAgPr3768xY8ZYnhX69NNP9eCDD+rvf/+7IiIiVK1aNXXo0EFvv/22JGnJkiWaOHGivvvuO/vZtSVLlkiSzp8/r4EDB6pMmTIKDAxUs2bN9N1339n3nXVG6p133lFoaKj8/Pz05JNP6rfffnP9FwPAEmEJQIHywgsvaNiwYTp06JBatmypP/74Q/Xq1dOnn36q77//XgMHDlSPHj20fft2y/288cYbql+/vvbs2aMhQ4bomWee0Q8//GC5zbhx4/TGG29o165d8vT0VN++fe3rPvjgA7366quaNm2adu/erYoVK2r+/PmW+wsJCdGBAwf0/fffZ7u+S5cuGjlypO655x4lJycrOTlZXbp0kTFGbdu2VUpKitatW6fdu3erbt26euSRR3T27Fn79keOHNHKlSu1du1arV+/Xnv37tWzzz5rWROAW5DPX+QL4A61ePFiExQUZF8+evSokWRmz559023btGljRo4caV9u0qSJef755+3LlSpVMt27d7cvZ2ZmmjJlyti/XT3rtfbs2WOMMWbz5s1GktmwYYN9m88++8xIMpcuXTLGGNOwYUPz7LPPOtTxwAMPmL/97W83rPPChQumTZs2RpKpVKmS6dKli1m0aJH5448/7HMmTJjgtI+NGzeawMBAh3nGGFOlShXzzjvv2Lfz8PAwP//8s339559/booUKWKSk5NvWBMA13FmCUCBUr9+fYflq1ev6tVXX1Xt2rVVqlQpFStWTPHx8Tpx4oTlfmrXrm3/c9blvlOnTuV4m7Jly0qSfZvDhw+rQYMGDvP/vPxn/v7++uyzz3TkyBGNHz9exYoV08iRI9WgQQNdvHjxhtvt3r1bFy5csB9v1s/Ro0f1448/2udVrFhRFSpUsC83atRImZmZTpcPAfw13OANoEDx9/d3WH7jjTc0a9YszZ49W7Vq1ZK/v7+GDx+uK1euWO7nzzeG22w2ZWZm5ngbm80mSQ7bZI1lMcZY7i9LlSpVVKVKFfXv31/jxo1TtWrVtGLFCvXp0yfb+ZmZmSpbtqy2bNnitK548eI3fJ2s+v5cJ4C/hrAEoED76quv1L59e3Xv3l3StSDx//7f/1NkZKRb64iIiNCOHTvUo0cP+9iuXbtc3k9YWJj8/Pz0+++/S5KKFi2qq1evOsypW7euUlJS5OnpqbCwsBvu68SJEzp58qTKlSsnSUpKSlKRIkVUrVo1l+sCcGOEJQAFWtWqVbV69WolJiaqRIkSmjlzplJSUtwelp577jkNGDBA9evXV1RUlFasWKF9+/apcuXKN9wmNjZWFy9eVJs2bVSpUiX99ttveuutt5Senq4WLVpIuhaejh49qr1796pChQoKCAhQ8+bN1ahRI3Xo0EHTpk1TRESETp48qXXr1qlDhw72S5U+Pj7q1auXZsyYodTUVA0bNkydO3d2y2MRgDsJ9ywBKNBeeukl1a1bVy1btlTTpk0VEhKiDh06uL2Obt26aezYsRo1apTq1q2ro0ePqnfv3vLx8bnhNk2aNNFPP/2knj17qnr16mrdurVSUlIUHx+viIgISVKnTp3UqlUrPfzww7rrrru0fPly2Ww2rVu3Tg899JD69u2ratWq6amnntKxY8cUHBxs33/VqlX1+OOPq02bNoqOjlbNmjU1b968PO8FcKexmZxedAcAOGjRooVCQkL0z3/+0+2vHRsbq48//pivbAHcgMtwAJADFy9e1IIFC9SyZUt5eHho+fLl2rBhgxISEvK7NAB5jLAEADmQdWls8uTJunz5siIiIrR69Wo1b948v0sDkMe4DAcAAGCBG7wBAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAs/H9+t/OVKqB6cAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(grad_norms)\n",
        "plt.xlabel(\"Training Step\")\n",
        "plt.ylabel(\"Gradient Norm\")\n",
        "plt.title(\"Gradient Norm over Training\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rq4krR3R8tv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7m_NRv1R8tv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
