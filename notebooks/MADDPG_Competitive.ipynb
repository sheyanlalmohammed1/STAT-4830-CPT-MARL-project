{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## Problem Setup\n",
        "This example demonstrates a multi-agent deep deterministic policy gradient (MADDPG) approach to a competitive environment where chasers aim to catch evaders. Each group of agents (chasers and evaders) has its own policy and value networks, trained either independently or in a mixed cooperative-competitive setting. It serves as our control when we try and integrate prospect theory into the policy gradient, seeing if we can get different results than the reward graphs below. Code is based from [https://pytorch.org/rl/0.6/tutorials/multiagent_competitive_ddpg.html]\n",
        "\n",
        "## Clear Problem Statement\n",
        "Train two chaser agents to minimize the evader’s cumulative reward while simultaneously training the evader agent to maximize its own cumulative reward. The environment runs for a fixed number of steps, and training can be halted for certain agents at a chosen iteration.\n",
        "\n",
        "## Mathematical Formulation\n",
        "- **Agent Policies**: $\\pi_i(\\mathbf{o_i}; \\theta_i)$ map observations $\\mathbf{o_i}$ to continuous actions.\n",
        "- **Value Function**: $Q_i(\\mathbf{o}, \\mathbf{a}; \\phi_i)$ estimates future return given all agents’ actions $\\mathbf{a}$ and observations $\\mathbf{o}$.\n",
        "- **Loss Functions**: DDPG losses incorporate actor and critic objectives, ensuring that each agent maximizes expected returns while considering centralized training and decentralized execution.\n",
        "- **Updates**: Soft updates are performed on target networks with \\(\\tau\\) for both the policy and value functions.\n",
        "\n",
        "## Data Requirements\n",
        "- Episodes of agent interactions, collected with exploration strategies (e.g., Gaussian noise).\n",
        "- Replay buffers per group for sampled training batches containing states, actions, rewards, and next states.\n",
        "\n",
        "## Success Metrics\n",
        "- Mean episode reward for each group (chasers and evaders), typically measured and plotted over training iterations.\n",
        "- Convergence or stabilization of the reward signal, indicating improved policy performance.\n"
      ],
      "metadata": {
        "id": "SCGeVy9NwjRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchrl\n",
        "!pip3 install vmas\n",
        "!pip3 install pettingzoo[mpe]==1.24.3\n",
        "!pip3 install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEJMg2fcV2Mi",
        "outputId": "67df16fe-8b52-45ba-cab6-bb7d8336eec9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchrl\n",
            "  Downloading torchrl-0.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (39 kB)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Collecting tensordict>=0.6.0 (from torchrl)\n",
            "  Downloading tensordict-0.6.2-cp311-cp311-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.6.0->torchrl) (3.10.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.0->torchrl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.0->torchrl) (3.0.2)\n",
            "Downloading torchrl-0.6.0-cp311-cp311-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.6.2-cp311-cp311-manylinux1_x86_64.whl (360 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.4/360.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, tensordict, torchrl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensordict-0.6.2 torchrl-0.6.0\n",
            "Collecting vmas\n",
            "  Downloading vmas-1.4.3.tar.gz (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from vmas) (2.5.1+cu124)\n",
            "Collecting pyglet<=1.5.27 (from vmas)\n",
            "  Downloading pyglet-1.5.27-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from vmas) (1.17.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->vmas) (3.0.2)\n",
            "Downloading pyglet-1.5.27-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: vmas\n",
            "  Building wheel for vmas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vmas: filename=vmas-1.4.3-py3-none-any.whl size=251650 sha256=85e4f097e09b2711b80289af2dcf6af4f7207ba3e98168470dc7a7e6ec8005aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/51/5c/071269951bab7c2c7bafb3f78ec6538b4a2b1c280b2eec365f\n",
            "Successfully built vmas\n",
            "Installing collected packages: pyglet, vmas\n",
            "Successfully installed pyglet-1.5.27 vmas-1.4.3\n",
            "Collecting pettingzoo==1.24.3 (from pettingzoo[mpe]==1.24.3)\n",
            "  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (1.0.0)\n",
            "Collecting pygame==2.3.0 (from pettingzoo[mpe]==1.24.3)\n",
            "  Downloading pygame-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (0.0.4)\n",
            "Downloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygame-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame, pettingzoo\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "Successfully installed pettingzoo-1.24.3 pygame-2.3.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Importing Required Libraries**\n",
        "This section imports essential modules for implementing MADDPG:  \n",
        "- **PyTorch** for deep learning operations.  \n",
        "- **`torchrl` modules** for multi-agent reinforcement learning, including environments, policies, collectors, and replay buffers.  \n",
        "- **`tensordict`** for structured tensor operations.  \n",
        "- **Matplotlib** for visualization.  \n",
        "- **`tqdm`** for progress tracking."
      ],
      "metadata": {
        "id": "RttHqpEoy-uW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yhec5pa7VzyM"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import tempfile\n",
        "\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tensordict import TensorDictBase\n",
        "\n",
        "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
        "from torch import multiprocessing\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyMemmapStorage, RandomSampler, ReplayBuffer\n",
        "\n",
        "from torchrl.envs import (\n",
        "    check_env_specs,\n",
        "    ExplorationType,\n",
        "    PettingZooEnv,\n",
        "    RewardSum,\n",
        "    set_exploration_type,\n",
        "    TransformedEnv,\n",
        "    VmasEnv,\n",
        ")\n",
        "\n",
        "from torchrl.modules import (\n",
        "    AdditiveGaussianModule,\n",
        "    MultiAgentMLP,\n",
        "    ProbabilisticActor,\n",
        "    TanhDelta,\n",
        ")\n",
        "\n",
        "from torchrl.objectives import DDPGLoss, SoftUpdate, ValueEstimators\n",
        "\n",
        "from torchrl.record import CSVLogger, PixelRenderTransform, VideoRecorder\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "    is_sphinx = __sphinx_build__\n",
        "except NameError:\n",
        "    is_sphinx = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Environment Setup & Hyperparameters**\n",
        "- **Seed & Device**: Sets the random seed for reproducibility and selects the appropriate device (GPU if available, otherwise CPU).  \n",
        "- **Sampling**: Defines frames collected per batch (`1,000`), total iterations (`50`), and total frames (`50,000`).  \n",
        "- **Training Control**: Stops evader training at `iteration_when_stop_training_evaders = 25`.  \n",
        "- **Replay Buffer**: Stores up to `1M` frames for experience replay.  \n",
        "- **Training Parameters**:  \n",
        "  - **Optimization**: `100` updates per iteration, batch size of `128`.  \n",
        "  - **Learning Rate**: `3e-4`, gradient clipping at `1.0`.  \n",
        "- **DDPG-Specific**: Uses discount factor (`γ = 0.99`) and soft update parameter (`τ = 0.005`)."
      ],
      "metadata": {
        "id": "xpSRX7gfzFeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Devices\n",
        "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
        "device = (\n",
        "    torch.device(0)\n",
        "    if torch.cuda.is_available() and not is_fork\n",
        "    else torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "# Sampling\n",
        "frames_per_batch = 1_000  # Number of team frames collected per sampling iteration\n",
        "n_iters = 50  # Number of sampling and training iterations\n",
        "total_frames = frames_per_batch * n_iters\n",
        "\n",
        "# We will stop training the evaders after this many iterations,\n",
        "# should be 0 <= iteration_when_stop_training_evaders <= n_iters\n",
        "iteration_when_stop_training_evaders = n_iters // 2\n",
        "\n",
        "# Replay buffer\n",
        "memory_size = 1_000_000  # The replay buffer of each group can store this many frames\n",
        "\n",
        "# Training\n",
        "n_optimiser_steps = 100  # Number of optimization steps per training iteration\n",
        "train_batch_size = 128  # Number of frames trained in each optimiser step\n",
        "lr = 3e-4  # Learning rate\n",
        "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
        "\n",
        "# DDPG\n",
        "gamma = 0.99  # Discount factor\n",
        "polyak_tau = 0.005  # Tau for the soft-update of the target network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eDQqQ5YV3Sw",
        "outputId": "b3b0b34e-3df7-491b-ead6-662449f7c687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Environment Configuration**\n",
        "- **Max Steps**: Each episode runs for `100` steps.  \n",
        "- **Agents & Obstacles**: `2` chasers, `1` evader, and `2` obstacles.  \n",
        "- **VMAS for Performance**:  \n",
        "  - If `use_vmas = True`, uses `VmasEnv` for efficient vectorized multi-agent simulation.  \n",
        "  - Otherwise, defaults to `PettingZooEnv` (parallel mode) for `simple_tag_v3`.  \n",
        "- **Vectorization**: `num_vmas_envs = frames_per_batch / max_steps` ensures efficient frame collection."
      ],
      "metadata": {
        "id": "qldjssDfy8l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 100  # Environment steps before done\n",
        "\n",
        "n_chasers = 2\n",
        "n_evaders = 1\n",
        "n_obstacles = 2\n",
        "\n",
        "use_vmas = True  # Set this to True for a great performance speedup\n",
        "\n",
        "if not use_vmas:\n",
        "    base_env = PettingZooEnv(\n",
        "        task=\"simple_tag_v3\",\n",
        "        parallel=True,  # Use the Parallel version\n",
        "        seed=seed,\n",
        "        # Scenario specific\n",
        "        continuous_actions=True,\n",
        "        num_good=n_evaders,\n",
        "        num_adversaries=n_chasers,\n",
        "        num_obstacles=n_obstacles,\n",
        "        max_cycles=max_steps,\n",
        "    )\n",
        "else:\n",
        "    num_vmas_envs = (\n",
        "        frames_per_batch // max_steps\n",
        "    )  # Number of vectorized environments. frames_per_batch collection will be divided among these environments\n",
        "    base_env = VmasEnv(\n",
        "        scenario=\"simple_tag\",\n",
        "        num_envs=num_vmas_envs,\n",
        "        continuous_actions=True,\n",
        "        max_steps=max_steps,\n",
        "        device=device,\n",
        "        seed=seed,\n",
        "        # Scenario specific\n",
        "        num_good_agents=n_evaders,\n",
        "        num_adversaries=n_chasers,\n",
        "        num_landmarks=n_obstacles,\n",
        "    )"
      ],
      "metadata": {
        "id": "3dx0KswwV97f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"group_map: {base_env.group_map}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9qc-A5yWGZJ",
        "outputId": "a1bccb9d-2d1f-4b4f-d12a-e903bdb2466d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group_map: {'adversary': ['adversary_0', 'adversary_1'], 'agent': ['agent_0']}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"action_spec:\", base_env.full_action_spec)\n",
        "print(\"reward_spec:\", base_env.full_reward_spec)\n",
        "print(\"done_spec:\", base_env.full_done_spec)\n",
        "print(\"observation_spec:\", base_env.observation_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYBvfAjqWH3j",
        "outputId": "b79fce98-9571-449d-e8ec-291a0996f1b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_spec: Composite(\n",
            "    adversary: Composite(\n",
            "        action: BoundedContinuous(\n",
            "            shape=torch.Size([10, 2, 2]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    agent: Composite(\n",
            "        action: BoundedContinuous(\n",
            "            shape=torch.Size([10, 1, 2]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 1])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "reward_spec: Composite(\n",
            "    adversary: Composite(\n",
            "        reward: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 2, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    agent: Composite(\n",
            "        reward: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 1, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 1])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "done_spec: Composite(\n",
            "    done: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "observation_spec: Composite(\n",
            "    adversary: Composite(\n",
            "        observation: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 2, 14]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    agent: Composite(\n",
            "        observation: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 1, 12]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 1])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"action_keys:\", base_env.action_keys)\n",
        "print(\"reward_keys:\", base_env.reward_keys)\n",
        "print(\"done_keys:\", base_env.done_keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGyVd6LTWJgu",
        "outputId": "6f77dab6-f7e3-4633-98a4-3005e42a8ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_keys: [('adversary', 'action'), ('agent', 'action')]\n",
            "reward_keys: [('adversary', 'reward'), ('agent', 'reward')]\n",
            "done_keys: ['done', 'terminated']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Environment Transformation**\n",
        "- **Wraps `base_env` with `TransformedEnv`** to apply reward processing.  \n",
        "- **`RewardSum` Aggregation**:  \n",
        "  - Uses `reward_keys` from `base_env` to sum rewards over time.  \n",
        "  - Resets rewards using `_reset` keys for each agent group.  \n",
        "- **Purpose**: Ensures proper reward tracking across multi-agent interactions."
      ],
      "metadata": {
        "id": "gOdgug90z7vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    RewardSum(\n",
        "        in_keys=base_env.reward_keys,\n",
        "        reset_keys=[\"_reset\"] * len(base_env.group_map.keys()),\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "q8e7iPn_WKvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3VPMV-UWLqf",
        "outputId": "0e5a68b1-0ee9-4c07-a1fb-536f9ba9bf0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-31 03:22:35,516 [torchrl][INFO] check_env_specs succeeded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_rollout_steps = 5\n",
        "rollout = env.rollout(n_rollout_steps)\n",
        "print(f\"rollout of {n_rollout_steps} steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BKZ9yjkWNlJ",
        "outputId": "1734f2a9-5a62-4bc3-f9fe-00721b941873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rollout of 5 steps: TensorDict(\n",
            "    fields={\n",
            "        adversary: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 5, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 5, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        agent: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 5, 1, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 5, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 5, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5, 1]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                adversary: TensorDict(\n",
            "                    fields={\n",
            "                        episode_reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        observation: Tensor(shape=torch.Size([10, 5, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "                    batch_size=torch.Size([10, 5, 2]),\n",
            "                    device=cuda:0,\n",
            "                    is_shared=True),\n",
            "                agent: TensorDict(\n",
            "                    fields={\n",
            "                        episode_reward: Tensor(shape=torch.Size([10, 5, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        observation: Tensor(shape=torch.Size([10, 5, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        reward: Tensor(shape=torch.Size([10, 5, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "                    batch_size=torch.Size([10, 5, 1]),\n",
            "                    device=cuda:0,\n",
            "                    is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10, 5]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "Shape of the rollout TensorDict: torch.Size([10, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Policy Network Setup**\n",
        "- **Iterates over agent groups** to create independent policies.  \n",
        "- **Defines `MultiAgentMLP`** for decentralized policies:\n",
        "  - **Observations & Actions**: Uses `env.observation_spec` and `env.full_action_spec`.\n",
        "  - **Decentralized Execution**: Each agent acts based on its local observation.\n",
        "  - **Parameter Sharing**: Controlled by `share_parameters_policy` (set to `True` for efficiency).\n",
        "  - **Architecture**: 2-layer MLP (`256` neurons per layer, `Tanh` activation).\n",
        "- **Wraps in `TensorDictModule`**:\n",
        "  - Reads observations from `TensorDict` and writes action parameters.  \n",
        "  - Allows structured tensor operations for multi-agent training."
      ],
      "metadata": {
        "id": "apB4yTml0Nf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_modules = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_policy = True  # Can change this based on the group\n",
        "\n",
        "    policy_net = MultiAgentMLP(\n",
        "        n_agent_inputs=env.observation_spec[group, \"observation\"].shape[\n",
        "            -1\n",
        "        ],  # n_obs_per_agent\n",
        "        n_agent_outputs=env.full_action_spec[group, \"action\"].shape[\n",
        "            -1\n",
        "        ],  # n_actions_per_agents\n",
        "        n_agents=len(agents),  # Number of agents in the group\n",
        "        centralised=False,  # the policies are decentralised (i.e., each agent will act from its local observation)\n",
        "        share_params=share_parameters_policy,\n",
        "        device=device,\n",
        "        depth=2,\n",
        "        num_cells=256,\n",
        "        activation_class=torch.nn.Tanh,\n",
        "    )\n",
        "\n",
        "    # Wrap the neural network in a :class:`~tensordict.nn.TensorDictModule`.\n",
        "    # This is simply a module that will read the ``in_keys`` from a tensordict, feed them to the\n",
        "    # neural networks, and write the\n",
        "    # outputs in-place at the ``out_keys``.\n",
        "\n",
        "    policy_module = TensorDictModule(\n",
        "        policy_net,\n",
        "        in_keys=[(group, \"observation\")],\n",
        "        out_keys=[(group, \"param\")],\n",
        "    )  # We just name the input and output that the network will read and write to the input tensordict\n",
        "    policy_modules[group] = policy_module"
      ],
      "metadata": {
        "id": "8bmzos-xWPzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Probabilistic Policy Definition**\n",
        "- **Wraps policy networks (`policy_modules`) in `ProbabilisticActor`** to handle stochastic action sampling.  \n",
        "- **Uses `TanhDelta` Distribution**:\n",
        "  - Ensures continuous action outputs stay within predefined bounds (`low`, `high`).  \n",
        "  - Helps stabilize training by keeping actions constrained.  \n",
        "- **Input & Output Keys**:\n",
        "  - Reads action parameters from `policy_modules` (`(group, \"param\")`).  \n",
        "  - Outputs final actions (`(group, \"action\")`).  \n",
        "- **Log Probabilities Disabled (`return_log_prob=False`)**:  \n",
        "  - Not needed for deterministic policy updates in DDPG."
      ],
      "metadata": {
        "id": "bvgRl6E81dFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    policy = ProbabilisticActor(\n",
        "        module=policy_modules[group],\n",
        "        spec=env.full_action_spec[group, \"action\"],\n",
        "        in_keys=[(group, \"param\")],\n",
        "        out_keys=[(group, \"action\")],\n",
        "        distribution_class=TanhDelta,\n",
        "        distribution_kwargs={\n",
        "            \"low\": env.full_action_spec[group, \"action\"].space.low,\n",
        "            \"high\": env.full_action_spec[group, \"action\"].space.high,\n",
        "        },\n",
        "        return_log_prob=False,\n",
        "    )\n",
        "    policies[group] = policy"
      ],
      "metadata": {
        "id": "vbHpMLXRWROv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Exploration Policy with Gaussian Noise**\n",
        "- **Adds exploration noise to deterministic policies** using `AdditiveGaussianModule`.  \n",
        "- **Purpose**: Encourages better exploration by injecting Gaussian noise into actions.  \n",
        "- **Annealing Strategy**:\n",
        "  - **Starts with `sigma_init = 0.9`** (high noise for exploration).  \n",
        "  - **Decays to `sigma_end = 0.1`** over `total_frames / 2` steps, reducing noise gradually.  \n",
        "- **Wrapped in `TensorDictSequential`**:\n",
        "  - First applies the base policy (`policies[group]`).  \n",
        "  - Then adds Gaussian noise to the output action (`(group, \"action\")`).  \n",
        "- **Ensures Smooth Transition**: High exploration at the start, stabilizing towards exploitation."
      ],
      "metadata": {
        "id": "_ttFAcMQ1nev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exploration_policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    exploration_policy = TensorDictSequential(\n",
        "        policies[group],\n",
        "        AdditiveGaussianModule(\n",
        "            spec=policies[group].spec,\n",
        "            annealing_num_steps=total_frames\n",
        "            // 2,  # Number of frames after which sigma is sigma_end\n",
        "            action_key=(group, \"action\"),\n",
        "            sigma_init=0.9,  # Initial value of the sigma\n",
        "            sigma_end=0.1,  # Final value of the sigma\n",
        "        ),\n",
        "    )\n",
        "    exploration_policies[group] = exploration_policy"
      ],
      "metadata": {
        "id": "IpDjZUtQWSeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Critic Network for Value Estimation**\n",
        "- **Defines critic networks for each agent group** to estimate state-action values (\\(Q\\)-values).  \n",
        "- **Centralized vs. Decentralized Critic**:\n",
        "  - **`MADDPG = True`**: Uses a centralized critic (multi-agent).  \n",
        "  - **`IDDPG = False`**: Uses an independent critic per agent.  \n",
        "- **Feature Concatenation (`cat_module`)**:\n",
        "  - Combines agent's observation and action into a single tensor (`(group, \"obs_action\")`).  \n",
        "- **Critic Network (`critic_module`)**:\n",
        "  - Takes concatenated state-action inputs and predicts a **single Q-value per agent**.  \n",
        "  - Uses a **2-layer MLP (256 neurons per layer, `Tanh` activation)**.  \n",
        "  - Supports parameter sharing (`share_parameters_critic = True`).  \n",
        "- **Final Critic Pipeline (`TensorDictSequential`)**:\n",
        "  - First applies **feature concatenation (`cat_module`)**.  \n",
        "  - Then passes through **`MultiAgentMLP` for value estimation** (`(group, \"state_action_value\")`)."
      ],
      "metadata": {
        "id": "_H8lIUgF1vzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "critics = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_critic = True  # Can change for each group\n",
        "    MADDPG = True  # IDDPG if False, can change for each group\n",
        "\n",
        "    # This module applies the lambda function: reading the action and observation entries for the group\n",
        "    # and concatenating them in a new ``(group, \"obs_action\")`` entry\n",
        "    cat_module = TensorDictModule(\n",
        "        lambda obs, action: torch.cat([obs, action], dim=-1),\n",
        "        in_keys=[(group, \"observation\"), (group, \"action\")],\n",
        "        out_keys=[(group, \"obs_action\")],\n",
        "    )\n",
        "\n",
        "    critic_module = TensorDictModule(\n",
        "        module=MultiAgentMLP(\n",
        "            n_agent_inputs=env.observation_spec[group, \"observation\"].shape[-1]\n",
        "            + env.full_action_spec[group, \"action\"].shape[-1],\n",
        "            n_agent_outputs=1,  # 1 value per agent\n",
        "            n_agents=len(agents),\n",
        "            centralised=MADDPG,\n",
        "            share_params=share_parameters_critic,\n",
        "            device=device,\n",
        "            depth=2,\n",
        "            num_cells=256,\n",
        "            activation_class=torch.nn.Tanh,\n",
        "        ),\n",
        "        in_keys=[(group, \"obs_action\")],  # Read ``(group, \"obs_action\")``\n",
        "        out_keys=[\n",
        "            (group, \"state_action_value\")\n",
        "        ],  # Write ``(group, \"state_action_value\")``\n",
        "    )\n",
        "\n",
        "    critics[group] = TensorDictSequential(\n",
        "        cat_module, critic_module\n",
        "    )  # Run them in sequence"
      ],
      "metadata": {
        "id": "LqVFCeRNWSfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_td = env.reset()\n",
        "for group, _agents in env.group_map.items():\n",
        "    print(\n",
        "        f\"Running value and policy for group '{group}':\",\n",
        "        critics[group](policies[group](reset_td)),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W7Qq-fBWZRq",
        "outputId": "d491d229-5100-4346-d467-116589bf1ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running value and policy for group 'adversary': TensorDict(\n",
            "    fields={\n",
            "        adversary: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                param: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        agent: TensorDict(\n",
            "            fields={\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 1]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "Running value and policy for group 'agent': TensorDict(\n",
            "    fields={\n",
            "        adversary: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                param: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        agent: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 1, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                param: Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 1]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Data Collection for Training**\n",
        "- **Combines all group exploration policies** into a single sequential module (`TensorDictSequential`), ensuring actions include exploration noise.  \n",
        "- **`SyncDataCollector` for Data Sampling**:\n",
        "  - Collects experience from the environment using **exploration policies**.  \n",
        "  - Runs on **`device` (GPU or CPU)** for efficiency.  \n",
        "  - **Frames per batch**: `1,000`, ensuring large enough updates per iteration.  \n",
        "  - **Total frames**: `50,000` (over `50` iterations).  \n",
        "- **Purpose**: Efficiently gathers on-policy experiences for training with replay buffers."
      ],
      "metadata": {
        "id": "iTfMG26J2L4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put exploration policies from each group in a sequence\n",
        "agents_exploration_policy = TensorDictSequential(*exploration_policies.values())\n",
        "\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    agents_exploration_policy,\n",
        "    device=device,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        ")"
      ],
      "metadata": {
        "id": "67asRrVjWa5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard in off policy algos for efficient data collections\n",
        "replay_buffers = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    replay_buffer = ReplayBuffer(\n",
        "        storage=LazyMemmapStorage(memory_size, device=\"cpu\"),\n",
        "        sampler=RandomSampler(),\n",
        "        batch_size=train_batch_size,\n",
        "    )\n",
        "    replay_buffer.append_transform(lambda batch: batch.to(\"cuda:0\"))\n",
        "    replay_buffers[group] = replay_buffer"
      ],
      "metadata": {
        "id": "NghMzg_3Wcky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Loss Calculation & Optimization**\n",
        "#### **Defining the Loss Function (`DDPGLoss`)**\n",
        "- **Uses separate actor and critic losses**:\n",
        "  - **`actor_network = policies[group]`**: Optimizes agent actions.\n",
        "  - **`value_network = critics[group]`**: Estimates state-action values.\n",
        "- **Target Network (`delay_value = True`)**:\n",
        "  - Uses a **target critic** for more stable learning.\n",
        "  - **Loss function**: Mean Squared Error (`\"l2\"`).\n",
        "- **Key Assignments**:\n",
        "  - **State-action value**: `(group, \"state_action_value\")`.\n",
        "  - **Reward Signal**: `(group, \"reward\")`.\n",
        "  - **Termination Handling**: `(group, \"done\")` and `(group, \"terminated\")`.\n",
        "- **TD(0) Estimator**: Uses **Temporal Difference (TD) learning** with discount factor `γ = 0.99`.\n",
        "\n",
        "#### **Target Network Updates**\n",
        "- **Soft update mechanism (`SoftUpdate`)**:\n",
        "  - **Gradually updates target networks** using `τ = 0.005`.\n",
        "  - Prevents drastic changes, improving stability.\n",
        "\n",
        "#### **Optimizers**\n",
        "- **Separate Adam optimizers for actor and critic networks**:\n",
        "  - **`loss_actor`**: Updates policy parameters.\n",
        "  - **`loss_value`**: Updates value network parameters.\n",
        "- **Learning rate (`lr = 3e-4`)** ensures smooth gradient updates."
      ],
      "metadata": {
        "id": "szedGF5b2g2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    loss_module = DDPGLoss(\n",
        "        actor_network=policies[group],  # Use the non-explorative policies\n",
        "        value_network=critics[group],\n",
        "        delay_value=True,  # Whether to use a target network for the value\n",
        "        loss_function=\"l2\",\n",
        "    )\n",
        "    loss_module.set_keys(\n",
        "        state_action_value=(group, \"state_action_value\"),\n",
        "        reward=(group, \"reward\"),\n",
        "        done=(group, \"done\"),\n",
        "        terminated=(group, \"terminated\"),\n",
        "    )\n",
        "    loss_module.make_value_estimator(ValueEstimators.TD0, gamma=gamma)\n",
        "\n",
        "    losses[group] = loss_module\n",
        "\n",
        "target_updaters = {\n",
        "    group: SoftUpdate(loss, tau=polyak_tau) for group, loss in losses.items()\n",
        "}\n",
        "\n",
        "optimisers = {\n",
        "    group: {\n",
        "        \"loss_actor\": torch.optim.Adam(\n",
        "            loss.actor_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "        \"loss_value\": torch.optim.Adam(\n",
        "            loss.value_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "    }\n",
        "    for group, loss in losses.items()\n",
        "}"
      ],
      "metadata": {
        "id": "bJ4u6U6EWfBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_batch(batch: TensorDictBase) -> TensorDictBase:\n",
        "    \"\"\"\n",
        "    If the `(group, \"terminated\")` and `(group, \"done\")` keys are not present, create them by expanding\n",
        "    `\"terminated\"` and `\"done\"`.\n",
        "    This is needed to present them with the same shape as the reward to the loss.\n",
        "    \"\"\"\n",
        "    for group in env.group_map.keys():\n",
        "        keys = list(batch.keys(True, True))\n",
        "        group_shape = batch.get_item_shape(group)\n",
        "        nested_done_key = (\"next\", group, \"done\")\n",
        "        nested_terminated_key = (\"next\", group, \"terminated\")\n",
        "        if nested_done_key not in keys:\n",
        "            batch.set(\n",
        "                nested_done_key,\n",
        "                batch.get((\"next\", \"done\")).unsqueeze(-1).expand((*group_shape, 1)),\n",
        "            )\n",
        "        if nested_terminated_key not in keys:\n",
        "            batch.set(\n",
        "                nested_terminated_key,\n",
        "                batch.get((\"next\", \"terminated\"))\n",
        "                .unsqueeze(-1)\n",
        "                .expand((*group_shape, 1)),\n",
        "            )\n",
        "    return batch"
      ],
      "metadata": {
        "id": "EjBvnOLGWgnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Approach: Training Loop & Optimization**\n",
        "#### **Progress Bar & Logging Setup**\n",
        "- **Uses `tqdm`** to track training iterations with episode rewards.  \n",
        "- **Initializes `episode_reward_mean_map`** to store reward trends per agent group.  \n",
        "- **Creates `train_group_map`** as a copy of `env.group_map`, allowing dynamic updates.\n",
        "\n",
        "#### **Main Training Loop**\n",
        "- **Iterates through `collector`** to process training batches.\n",
        "- **Preprocesses Data (`process_batch`)**:\n",
        "  - Expands done/terminated keys for proper loss computation.\n",
        "  - **Excludes data from other groups** to isolate training signals.\n",
        "  - **Reshapes batch** to align with replay buffer dimensions.\n",
        "- **Stores Data in Replay Buffer (`replay_buffers[group].extend(group_batch)`)**.\n",
        "\n",
        "#### **Optimization Steps**\n",
        "- **Samples batches (`n_optimiser_steps = 100`)** from replay buffer.\n",
        "- **Computes & Backpropagates Loss**:\n",
        "  - Extracts actor (`loss_actor`) and critic (`loss_value`) loss.\n",
        "  - **Clips gradients (`max_grad_norm = 1.0`)** to prevent instability.\n",
        "  - **Optimizes parameters with Adam**, resetting gradients after each step.\n",
        "- **Soft Updates (`target_updaters[group].step()`)**:\n",
        "  - Gradually syncs target networks using `τ = 0.005`.\n",
        "\n",
        "#### **Adaptive Exploration**\n",
        "- **Anneals exploration noise (`sigma`)** based on the number of frames processed.\n",
        "\n",
        "#### **Training Halting Condition**\n",
        "- **Stops training evaders after `iteration_when_stop_training_evaders = 25`**.\n",
        "\n",
        "#### **Logging & Progress Tracking**\n",
        "- **Computes mean episode reward** for each group.\n",
        "- **Updates `tqdm` progress bar** with latest reward values."
      ],
      "metadata": {
        "id": "CHXNfxaJ2sQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = tqdm(\n",
        "    total=n_iters,\n",
        "    desc=\", \".join(\n",
        "        [f\"episode_reward_mean_{group} = 0\" for group in env.group_map.keys()]\n",
        "    ),\n",
        ")\n",
        "episode_reward_mean_map = {group: [] for group in env.group_map.keys()}\n",
        "train_group_map = copy.deepcopy(env.group_map)\n",
        "\n",
        "# Training/collection iterations\n",
        "for iteration, batch in enumerate(collector):\n",
        "    current_frames = batch.numel()\n",
        "    batch = process_batch(batch)  # Util to expand done keys if needed\n",
        "    # Loop over groups\n",
        "    for group in train_group_map.keys():\n",
        "        group_batch = batch.exclude(\n",
        "            *[\n",
        "                key\n",
        "                for _group in env.group_map.keys()\n",
        "                if _group != group\n",
        "                for key in [_group, (\"next\", _group)]\n",
        "            ]\n",
        "        )  # Exclude data from other groups\n",
        "        group_batch = group_batch.reshape(\n",
        "            -1\n",
        "        )  # This just affects the leading dimensions in batch_size of the tensordict\n",
        "        replay_buffers[group].extend(group_batch)\n",
        "\n",
        "        for _ in range(n_optimiser_steps):\n",
        "            subdata = replay_buffers[group].sample()\n",
        "            loss_vals = losses[group](subdata)\n",
        "\n",
        "            for loss_name in [\"loss_actor\", \"loss_value\"]:\n",
        "                loss = loss_vals[loss_name]\n",
        "                optimiser = optimisers[group][loss_name]\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Optional\n",
        "                params = optimiser.param_groups[0][\"params\"]\n",
        "                torch.nn.utils.clip_grad_norm_(params, max_grad_norm)\n",
        "\n",
        "                optimiser.step()\n",
        "                optimiser.zero_grad()\n",
        "\n",
        "            # Soft-update the target network\n",
        "            target_updaters[group].step()\n",
        "\n",
        "        # Exploration sigma anneal update\n",
        "        exploration_policies[group][-1].step(current_frames)\n",
        "\n",
        "    # Stop training a certain group when a condition is met (e.g., number of training iterations)\n",
        "    if iteration == iteration_when_stop_training_evaders:\n",
        "        del train_group_map[\"agent\"]\n",
        "\n",
        "    # Logging\n",
        "    for group in env.group_map.keys():\n",
        "        episode_reward_mean = (\n",
        "            batch.get((\"next\", group, \"episode_reward\"))[\n",
        "                batch.get((\"next\", group, \"done\"))\n",
        "            ]\n",
        "            .mean()\n",
        "            .item()\n",
        "        )\n",
        "        episode_reward_mean_map[group].append(episode_reward_mean)\n",
        "\n",
        "    pbar.set_description(\n",
        "        \", \".join(\n",
        "            [\n",
        "                f\"episode_reward_mean_{group} = {episode_reward_mean_map[group][-1]}\"\n",
        "                for group in env.group_map.keys()\n",
        "            ]\n",
        "        ),\n",
        "        refresh=False,\n",
        "    )\n",
        "    pbar.update()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "rwLjnzsLWjzS",
        "outputId": "c760a3a6-2e0e-445c-d25d-6d7f5ff354a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "episode_reward_mean_adversary = 60.0, episode_reward_mean_agent = -60.0:  58%|█████▊    | 29/50 [02:46<01:46,  5.08s/it]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2efc81cf0328>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Training/collection iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mcurrent_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Util to expand done keys if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/collectors/collectors.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorDictBase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/collectors/collectors.py\u001b[0m in \u001b[0;36miterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frames\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m                 \u001b[0mtensordict_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtensordict_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m                     \u001b[0;31m# if a replay buffer is passed, there is no tensordict_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/_utils.py\u001b[0m in \u001b[0;36munpack_rref_and_invoke_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os_is_windows\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_rpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyRRef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0munpack_rref_and_invoke_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/collectors/collectors.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                     \u001b[0menv_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shuttle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0menv_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_next_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_and_maybe_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shuttle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mstep_and_maybe_reset\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m             \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2862\u001b[0;31m         \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2863\u001b[0m         \u001b[0;31m# done and truncated are in done_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \u001b[0;31m# We read if any key is done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mnext_preset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_proc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_preset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mnext_preset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mtensordict_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_preset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# tensordict could already have a \"next\" key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/libs/vmas.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vmas/simulator/environment/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# advance world state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vmas/simulator/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2007\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m                 \u001b[0;31m# integrate physical state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_integrate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m         \u001b[0;31m# update non-differentiable comm state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vmas/simulator/core.py\u001b[0m in \u001b[0;36m_integrate_state\u001b[0;34m(self, entity, substep)\u001b[0m\n\u001b[1;32m   2881\u001b[0m                 [\n\u001b[1;32m   2882\u001b[0m                     (\n\u001b[0;32m-> 2883\u001b[0;31m                         \u001b[0mnew_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x_semidim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x_semidim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2884\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x_semidim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m                         \u001b[0;32melse\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our \"test\" to make sure our agents are trainng, we see after the agent stops training the adversaries rewards are increasing and then while it is trainng their rewards both go to 0"
      ],
      "metadata": {
        "id": "UdxfvvGb2uRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 1)\n",
        "for i, group in enumerate(env.group_map.keys()):\n",
        "    axs[i].plot(episode_reward_mean_map[group], label=f\"Episode reward mean {group}\")\n",
        "    axs[i].set_ylabel(\"Reward\")\n",
        "    axs[i].axvline(\n",
        "        x=iteration_when_stop_training_evaders,\n",
        "        label=\"Agent (evader) stop training\",\n",
        "        color=\"orange\",\n",
        "    )\n",
        "    axs[i].legend()\n",
        "axs[-1].set_xlabel(\"Training iterations\")\n",
        "plt.show()\n",
        "print(env.group_map.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "N_voZiw3WnTw",
        "outputId": "21fd3e13-53a6-4531-e8d1-5529b9991e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['adversary', 'agent'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBIAaI_SXoSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O1CunWRfcHKU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}